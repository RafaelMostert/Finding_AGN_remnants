{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39eb84ba",
   "metadata": {},
   "source": [
    "# Notebook for the manuscript: Finding AGN remnants with machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbcfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import DetCurveDisplay, RocCurveDisplay,plot_roc_curve,plot_precision_recall_curve\n",
    "from dataclasses import dataclass\n",
    "import dataclasses\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import mahotas as mh\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "from astropy.wcs import WCS\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import hdbscan\n",
    "import os\n",
    "import sys\n",
    "import pyvo\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Insert path to pinklib.postprocessing.py for support functions\n",
    "# Library available here:\n",
    "sys.path.insert(0, '<path_to_pinklib_folder>')\n",
    "import postprocessing as post\n",
    "from pinklib.postprocessing import CutoutSettings\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier,GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from joblib import Parallel, logger\n",
    "from sklearn.base import is_classifier, clone\n",
    "from sklearn.utils import indexable, check_random_state, _safe_indexing\n",
    "from sklearn.utils.validation import _check_fit_params\n",
    "from sklearn.utils.fixes import delayed\n",
    "from sklearn.utils.metaestimators import _safe_split\n",
    "from sklearn.metrics import check_scoring\n",
    "from sklearn.model_selection._split import check_cv\n",
    "from sklearn.metrics import recall_score, make_scorer, SCORERS, fbeta_score\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0171d49",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769e29bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import data, set up file locations and names\n",
    "# Figures directory\n",
    "paper_fig_dir = 'figures'\n",
    "cat_dir = 'catalogues'\n",
    "data_directory = 'remnants'\n",
    "comp_path=os.path.join(cat_dir,'LOFAR_HBA_T1_DR1_merge_ID_v1.2.comp.h5')\n",
    "gaul_path=os.path.join(cat_dir,'LOFAR_HBA_T1_DR1_catalog_v0.99.gaus.h5')\n",
    "vac_path=os.path.join(cat_dir,'LOFAR_HBA_T1_DR1_merge_ID_optical_f_v1.2.h5')\n",
    "# Path to directory that contains fits-files of all Stokes-I image pointings.\n",
    "LoTSS_DR2_dir='LoTSS_DR2/RA0h_field'\n",
    "\n",
    "comp_cat = pd.read_hdf(comp_path,'df')\n",
    "gaul_cat = pd.read_hdf(gaul_path,'df')\n",
    "value_added_catalogue = pd.read_hdf(vac_path,'df')\n",
    "\n",
    "# File name conventions used\n",
    "################################################\n",
    "# Name of the fits file\n",
    "fits_filename = 'mosaic-blanked'\n",
    "fits_rms_filename = 'mosaic.rms'\n",
    "fits_new_catalogue_filename = 'mosaic.cat_new'\n",
    "# Name of the trained SOM subdirectory\n",
    "trained_subdirectory = None\n",
    "# output filename\n",
    "cutouts_filename = 'LoTSS_DR2_value_added_variable'\n",
    "cutouts_filename_final = cutouts_filename +'_final'\n",
    "rms_cutouts_filename = 'LoTSS_DR2_value_added_variable_rms'\n",
    "rms_cutouts_filename_final = rms_cutouts_filename +'_final'\n",
    "\n",
    "# Name of the output directory, where your trained SOM and your SOM-mapping should reside\n",
    "output_directory = os.path.join(data_directory,'output')\n",
    "figures_dir = os.path.join(output_directory, 'figures')\n",
    "map_dir = os.path.join(output_directory,'maps')\n",
    "run_dir = os.path.join(data_directory,'run')\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "os.makedirs(map_dir, exist_ok=True)\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "\n",
    "# Cut-out parameters\n",
    "################################################\n",
    "# Resolution for each cutout in degrees\n",
    "resolution = 0.0085/60# Note: we already hit bedrock resolution (the highest res. hips-files) so increasing it won't help.\n",
    "apply_clipping = False\n",
    "# Enable scaling?\n",
    "log_scaling = False\n",
    "sinh_scaling = False\n",
    "rotated_size_arcsec = 100\n",
    "rotated_size = 67 # fits-pixels\n",
    "fullsize = 95 #85 # fits-pixels (rotated_size * sqqrt(2))\n",
    "test_fraction = 0.3\n",
    "random_seed = 42\n",
    "lower_sigma_limit = 1.5 # Lower clip bound is defined as local rms * lower_sigma_limit\n",
    "# Name of the binary file\n",
    "cutouts_bin_name = f'cutouts_preprocessed_rotatedsize_{rotated_size_arcsec}arcsec'\n",
    "################################################\n",
    "gpu_id = 0\n",
    "\n",
    "# # trained SOM parameters\n",
    "# ################################################\n",
    "layout = 'quadratic'\n",
    "som_label = '- 10x10 cyclic'\n",
    "number_of_channels = 1\n",
    "som_width, som_height, som_depth = 10, 10, 1\n",
    "# ################################################\n",
    "\n",
    "# Catalogue parameters\n",
    "################################################\n",
    "mosaic_id_key,ra_key,dec_key = 'Mosaic_ID', 'RA', 'DEC'\n",
    "################################################\n",
    "\n",
    "# Outliers parameters\n",
    "################################################\n",
    "debug = False\n",
    "number_of_outliers_to_show = 100\n",
    "max_number_of_images_to_show = 10\n",
    "#####################################\n",
    "\n",
    "\n",
    "\n",
    "lgz_size = value_added_catalogue['LGZ_Size'].fillna(0)\n",
    "lgz_width = value_added_catalogue['LGZ_Width'].fillna(0)\n",
    "lgz_PA = value_added_catalogue['LGZ_PA'].fillna(0)\n",
    "maj_size = value_added_catalogue['Maj'].fillna(0)\n",
    "min_size = value_added_catalogue['Min'].fillna(0)\n",
    "PA = value_added_catalogue['PA'].fillna(0)\n",
    "value_added_catalogue['source_size'] = (lgz_size + maj_size).astype(float)\n",
    "value_added_catalogue['source_width'] = (lgz_width+min_size).astype(float)\n",
    "value_added_catalogue['source_PA'] = (lgz_PA+PA).astype(float)\n",
    "\n",
    "fits_path_LoTSS = os.path.join(\n",
    "    'LoTSS_DR2/RA0h_field/P206+50', \n",
    "    fits_filename+'.fits')\n",
    "image, hdr = post.load_fits(fits_path_LoTSS, dimensions_normal=False)\n",
    "wcs = WCS(hdr,naxis=2)\n",
    "angular_resolution_LoTSS = abs(hdr['CDELT1'])*3600\n",
    "print(f'Angular resolution: {angular_resolution_LoTSS:.2f} arcsec/pixels')\n",
    "\n",
    "print(\"# sources in HETDEX bigger than 60\\\":\", \n",
    "      np.sum(value_added_catalogue['source_size'] > 60))\n",
    "\n",
    "# Load Marisa's sample of visually inspected AGN remnant candidates\n",
    "remnant_names = pd.read_csv('datasets/151remnants-candidates-hetdex.txt',\n",
    "                            names=['Source_Name'],header=None).Source_Name.values\n",
    "print(f\"We have {len(remnant_names)} remnants.\")\n",
    "hetdex_bigger_than60arcsec = value_added_catalogue[value_added_catalogue['source_size']>60]\n",
    "calibration_set = value_added_catalogue[value_added_catalogue.Source_Name.isin(remnant_names)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbcf2ea",
   "metadata": {},
   "source": [
    "# Adjust random forest code such that no data leakage occurs\n",
    "The cell below makes sure that the SOM remnant ratio and the Haralick cluster ratios\n",
    "do not leak between training and validation and between training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class plotSetting:\n",
    "    normalize: bool\n",
    "    zoom_in: bool\n",
    "    highlight_neurons: list = dataclasses.field(default_factory=list)\n",
    "    highlight_colors: list = dataclasses.field(default_factory=list)\n",
    "    legend_list: list = dataclasses.field(default_factory=list)\n",
    "\n",
    "\n",
    "def insert_local_remnant_ratios(features_original, labels_,debug=False):\n",
    "    features_ = deepcopy(features_original)\n",
    "    bmn_train = [int(feat[0]) for feat in features_]\n",
    "    bmn_train_remnants = [bmn for (bmn,label) \n",
    "                                in zip(bmn_train,labels_) if label]\n",
    "    all_labels, all_counts = np.unique(bmn_train, return_counts=True)\n",
    "    remnant_labels, remnant_counts = np.unique(bmn_train_remnants, return_counts=True)\n",
    "    all_dict = {l:c for l, c in zip(all_labels, all_counts)}\n",
    "    remnant_dict = {l:c for l, c in zip(remnant_labels, remnant_counts)}\n",
    "    # Create abs and ratios\n",
    "    remnants_per_mapped_to_neuron = np.array([remnant_dict.get(key, 0) for key in bmn_train])\n",
    "    remnants_per_mapped_to_neuron_ratio = np.array([remnant_dict.get(key, 0)/all_dict.get(key, 1)\n",
    "                                           for key in bmn_train])\n",
    "    \n",
    "    features_T = features_.T\n",
    "    features_T[0] = remnants_per_mapped_to_neuron\n",
    "    features_T[1] = remnants_per_mapped_to_neuron_ratio\n",
    "    \n",
    "    ################################# HARALICK Ratios\n",
    "    # Get haralick cluster labels for the whole set and for the remnant\n",
    "    hara_hard_train = [int(feat[-1]) for feat in features_]\n",
    "    hara_hard_train_remnants = [hara_label for (hara_label,label) \n",
    "                                in zip(hara_hard_train,labels_) if label]\n",
    "    # Count # of sources in each cluster for the whole set and for the remnant\n",
    "    remnant_hara_hard_labels, remnant_hara_hard_counts = np.unique(hara_hard_train_remnants,\n",
    "                                                         return_counts=True)\n",
    "    all_hara_hard_labels, all_hara_hard_counts = np.unique(hara_hard_train,return_counts=True)\n",
    "\n",
    "    # Insert counts into dict\n",
    "    remnant_dict_hard = {l:c for l, c in zip(remnant_hara_hard_labels, remnant_hara_hard_counts)}\n",
    "    all_dict_hard = {l:c for l, c in zip(all_hara_hard_labels, all_hara_hard_counts)}\n",
    "\n",
    "    # Create list of ratios.\n",
    "    hara_hard_ratios = [remnant_dict_hard.get(key, 0)/all_dict_hard.get(key, 1) \n",
    "                   for key in hara_hard_train]\n",
    "    features_T[-1] = hara_hard_ratios\n",
    "    \n",
    "    \n",
    "    if debug:\n",
    "        abs_bmn_debug = np.array([remnant_dict.get(key, 0) for key in range(25)])\n",
    "        rel_bmn_debug = np.array([remnant_dict.get(key, 0)/all_dict.get(key, 1)\n",
    "                           for key in range(25)])\n",
    "        hara_hard_debug = [remnant_dict_hard.get(key, 0)/all_dict_hard.get(key, 1) \n",
    "                   for key in range(-1,6)]\n",
    "        hara_soft_debug = [remnant_dict_soft.get(key, 0)/all_dict_soft.get(key, 1) \n",
    "                   for key in range(6)]\n",
    "\n",
    "        plt.imshow(abs_bmn_debug.reshape(5,5))\n",
    "        plt.title('SOM remnant')\n",
    "        plt.show()\n",
    "        plt.imshow(rel_bmn_debug.reshape(5,5))\n",
    "        plt.title('SOM remnant ratio')\n",
    "        plt.show()\n",
    "        plt.bar(list(range(-1,6)),hara_hard_debug)\n",
    "        plt.title('Hara hard remnant ratio')\n",
    "        plt.show()\n",
    "        plt.bar(list(range(6)),hara_soft_debug)\n",
    "        plt.title('Hara soft remnant ratio')\n",
    "        plt.show()\n",
    "    return features_T.T, remnant_dict, all_dict, remnant_dict_hard, all_dict_hard\n",
    "\n",
    "\n",
    "\n",
    "def custom_permutation_test_score(estimator,X,y,*,groups=None,cv=None,n_permutations=100,\n",
    "    n_jobs=-1,random_state=0,verbose=0,scoring=None,fit_params=None,):\n",
    "    \"\"\"Evaluate the significance of a cross-validated score with permutations.\n",
    "    Permutes targets to generate 'randomized data' and compute the empirical\n",
    "    p-value against the null hypothesis that features and targets are\n",
    "    independent.\n",
    "    The p-value represents the fraction of randomized data sets where the\n",
    "    estimator performed as well or better than in the original data. A small\n",
    "    p-value suggests that there is a real dependency between features and\n",
    "    targets which has been used by the estimator to give good predictions.\n",
    "    A large p-value may be due to lack of real dependency between features\n",
    "    and targets or the estimator was not able to use the dependency to\n",
    "    give good predictions.\n",
    "    Read more in the :ref:`User Guide <permutation_test_score>`.\"\"\"\n",
    "    X, y, groups = indexable(X, y, groups)\n",
    "\n",
    "    cv = check_cv(cv, y, classifier=is_classifier(estimator))\n",
    "    scorer = check_scoring(estimator, scoring=scoring)\n",
    "    random_state = check_random_state(random_state)\n",
    "\n",
    "    # We clone the estimator to make sure that all the folds are\n",
    "    # independent, and that it is pickle-able.\n",
    "    score = _custom_permutation_test_score(\n",
    "        clone(estimator), X, y, y, groups, cv, scorer, fit_params=fit_params\n",
    "    )\n",
    "    permutation_scores = Parallel(n_jobs=n_jobs, verbose=verbose)(\n",
    "        delayed(_custom_permutation_test_score)(\n",
    "            clone(estimator),\n",
    "            X,\n",
    "            y,\n",
    "            _shuffle(y, groups, random_state),\n",
    "            groups,\n",
    "            cv,\n",
    "            scorer,\n",
    "            fit_params=fit_params,\n",
    "        )\n",
    "        for _ in range(n_permutations)\n",
    "    )\n",
    "    permutation_scores = np.array(permutation_scores)\n",
    "    pvalue = (np.sum(permutation_scores >= score) + 1.0) / (n_permutations + 1)\n",
    "    return score, permutation_scores, pvalue\n",
    "\n",
    "def insert_local_test_ratios(features_test, remnant_dict, all_dict, \\\n",
    "                                            remnant_dict_hard, all_dict_hard):\n",
    "    # Isolate BMN\n",
    "    features_ = deepcopy(features_test)\n",
    "    bmn_testsubset = [int(feat[0]) for feat in features_]\n",
    "    \n",
    "    # Create abs and ratios\n",
    "    remnants_per_mapped_to_neuron = [remnant_dict.get(key, 0) for key in bmn_testsubset]\n",
    "    remnants_per_mapped_to_neuron_ratio = [remnant_dict.get(key, 0)/all_dict.get(key, 1)\n",
    "                                           for key in bmn_testsubset]\n",
    "    \n",
    "    features_T = features_.T\n",
    "    features_T[0] = remnants_per_mapped_to_neuron\n",
    "    features_T[1] = remnants_per_mapped_to_neuron_ratio\n",
    "    \n",
    "    ################################# HARALICK Ratios\n",
    "    # Get haralick cluster labels for the whole set and for the remnant subset\n",
    "    hara_hard_testsubset = [int(feat[-1]) for feat in features_]\n",
    "    # Create list of ratios.\n",
    "    hara_hard_ratios = [remnant_dict_hard.get(key, 0)/all_dict_hard.get(key, 1) \n",
    "                   for key in hara_hard_testsubset]\n",
    "    features_T[-1] = hara_hard_ratios\n",
    "\n",
    "    return features_T.T\n",
    "\n",
    "def _custom_permutation_test_score(estimator, X, real_y, y, groups, cv, scorer, fit_params):\n",
    "    \"\"\"Auxiliary function for custom_permutation_test_score\"\"\"\n",
    "    # Adjust length of sample weights\n",
    "    fit_params = fit_params if fit_params is not None else {}\n",
    "    avg_score = []\n",
    "    for train, test in cv.split(X, y, groups):\n",
    "        X_train_before, y_train = _safe_split(estimator, X, y, train)\n",
    "        X_test_before, y_test = _safe_split(estimator, X, y, test, train)\n",
    "        _, real_y_train = _safe_split(estimator, X, real_y, train)\n",
    "        X_train, remnant_dict, all_dict, remnant_dict_hard, all_dict_hard, \\\n",
    "            = insert_local_remnant_ratios(X_train_before,real_y_train)\n",
    "        X_test = insert_local_test_ratios(X_test_before, remnant_dict, all_dict, \\\n",
    "                                            remnant_dict_hard, all_dict_hard)\n",
    "        \n",
    "        fit_params = _check_fit_params(X, fit_params, train)\n",
    "        estimator.fit(X_train, y_train, **fit_params)\n",
    "        avg_score.append(scorer(estimator, X_test, y_test))\n",
    "    return np.mean(avg_score)\n",
    "\n",
    "\n",
    "def _shuffle(y, groups, random_state):\n",
    "    \"\"\"Return a shuffled copy of y eventually shuffle among same groups.\"\"\"\n",
    "    if groups is None:\n",
    "        indices = random_state.permutation(len(y))\n",
    "    else:\n",
    "        indices = np.arange(len(groups))\n",
    "        for group in np.unique(groups):\n",
    "            this_mask = groups == group\n",
    "            indices[this_mask] = random_state.permutation(indices[this_mask])\n",
    "    return _safe_indexing(y, indices)\n",
    "\n",
    "def classification_report_to_latex(report,\n",
    "                                   target_names=['noncandidate','AGN remnant candidate']):\n",
    "    table_boilerplate=r\"\"\"\n",
    "\\begin{table}\n",
    "\\centering\n",
    "\\caption{caption}\n",
    "\\label{tab:perf}\n",
    "\\begin{tabular}{rrrrr}\n",
    "\\hline\\hline\n",
    "  & precision & recall & f1-score & support \\\\\n",
    "\\hline\"\"\"\n",
    "    for target in target_names:\n",
    "        t = report[target]\n",
    "        table_boilerplate+=fr\"\"\"\n",
    "{target}  & ${t['precision']:.2f}$ & ${t['recall']:.2f}$ & ${t['f1-score']:.2f}$ & ${t['support']}$ \\\\\"\"\"  \n",
    "    t = report['weighted avg']\n",
    "    table_boilerplate+=fr\"\"\"\n",
    "  &  &  & &  \\\\\n",
    "weighted average  & ${t['precision']:.2f}$ & ${t['recall']:.2f}$ & ${t['f1-score']:.2f}$ & ${t['support']}$ \\\\\"\"\"  \n",
    "    table_boilerplate+=fr\"\"\"\n",
    "\\hline\n",
    "accuracy & ${report['accuracy']:.2f}$ & & &  ${t['support']}$ \\\\\"\"\"  \n",
    "    table_boilerplate+=\"\"\"\n",
    "\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\"\"\"\n",
    "    return table_boilerplate\n",
    "\n",
    "def mask_outside_gaussian(gaussians,astropy_cutout):\n",
    "    # Create indices\n",
    "    yi, xi = np.indices(astropy_cutout.shape)\n",
    "        \n",
    "    model = np.zeros(astropy_cutout.shape,dtype=bool)\n",
    "    for g in gaussians:\n",
    "        gau = g(xi,yi)\n",
    "        max_gau = np.max(gau)\n",
    "        model[gau < 0.01*max_gau] = True\n",
    "    astropy_cutout[model] = np.nan\n",
    "                       \n",
    "    return model, astropy_cutout\n",
    "\n",
    "\n",
    "def get_significance_stats(image, cutout_wcs, source, cat, noise,debug=False):\n",
    "    \"\"\"Mask everything outside source and return stats on the unmasked source.\n",
    "    params:\n",
    "        cat = a source catalogue in the pandas dataframe format\"\"\"\n",
    "    use_source_size=True\n",
    "    # retrieve pixel resolution as in practice it often varies between cutouts,\n",
    "    # especially the RA can have less pixels representing a fixed set of arcseconds\n",
    "    arcsec_per_pixel_RA, arcsec_per_pixel_DEC = post.return_cutout_pixel_resolution(\n",
    "            image, cutout_wcs, verbose=False)\n",
    "    if debug:\n",
    "        print(\"angular res, ra, dec:\", arcsec_per_pixel_RA,arcsec_per_pixel_DEC)\n",
    "\n",
    "    # create subset of gaussian list\n",
    "    ra, dec = source.RA, source.DEC\n",
    "\n",
    "    sr = image.shape[0]*arcsec_per_pixel_RA/3600\n",
    "    sd = image.shape[1]*arcsec_per_pixel_DEC/3600\n",
    "\n",
    "    local_cat = cat[source.Source_Name == cat.Source_Name]\n",
    "    if debug:\n",
    "        print(\"Rough neighbour removal found this many neighbours:\",len(local_cat))\n",
    "          \n",
    "    # Create gaussians\n",
    "    gaussians = post.extract_gaussian_parameters_from_component_catalogue(local_cat,cutout_wcs,\n",
    "            use_source_size=use_source_size)\n",
    "    # Mask all outside\n",
    "    model, residual = mask_outside_gaussian(gaussians,image)\n",
    "    if debug:\n",
    "        plt.title('model')\n",
    "        plt.imshow(model)\n",
    "        plt.show()\n",
    "        plt.title('residual')\n",
    "        plt.imshow(residual)\n",
    "        plt.show()\n",
    "    med = np.nanmedian(residual)/noise\n",
    "    return residual, med"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d012d42",
   "metadata": {},
   "source": [
    "## Implement gridsearch such that no data leakage occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from collections import defaultdict\n",
    "from collections.abc import Mapping, Sequence, Iterable\n",
    "from functools import partial, reduce\n",
    "from itertools import product\n",
    "import numbers\n",
    "import operator\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import suppress\n",
    "from traceback import format_exc\n",
    "import scipy.sparse as sp\n",
    "from joblib import Parallel, delayed, logger\n",
    "\n",
    "from sklearn.base import is_classifier, clone\n",
    "from sklearn.utils import indexable, check_random_state, _safe_indexing\n",
    "from sklearn.utils.validation import _check_fit_params\n",
    "from sklearn.utils.validation import _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "from sklearn.utils.metaestimators import _safe_split\n",
    "from sklearn.metrics._scorer import _check_multimetric_scoring, _MultimetricScorer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy.ma import MaskedArray\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.base import BaseEstimator, is_classifier, clone\n",
    "from sklearn.base import MetaEstimatorMixin\n",
    "from sklearn.model_selection._split import check_cv\n",
    "from sklearn.model_selection._validation import _aggregate_score_dicts\n",
    "from sklearn.model_selection._validation import _insert_error_scores\n",
    "from sklearn.model_selection._validation import _normalize_score_results\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "from sklearn.utils._tags import _safe_tags\n",
    "from sklearn.utils.validation import indexable, check_is_fitted, _check_fit_params\n",
    "from sklearn.utils.fixes import delayed\n",
    "from sklearn.metrics._scorer import _check_multimetric_scoring\n",
    "\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "from sklearn.utils.metaestimators import if_delegate_has_method\n",
    "from sklearn.metrics import check_scoring\n",
    "from sklearn.utils import deprecated\n",
    "\n",
    "def _check_param_grid(param_grid):\n",
    "    if hasattr(param_grid, 'items'):\n",
    "        param_grid = [param_grid]\n",
    "\n",
    "    for p in param_grid:\n",
    "        for name, v in p.items():\n",
    "            if isinstance(v, np.ndarray) and v.ndim > 1:\n",
    "                raise ValueError(\"Parameter array should be one-dimensional.\")\n",
    "\n",
    "            if (isinstance(v, str) or\n",
    "                    not isinstance(v, (np.ndarray, Sequence))):\n",
    "                raise ValueError(\"Parameter grid for parameter ({0}) needs to\"\n",
    "                                 \" be a list or numpy array, but got ({1}).\"\n",
    "                                 \" Single values need to be wrapped in a list\"\n",
    "                                 \" with one element.\".format(name, type(v)))\n",
    "\n",
    "            if len(v) == 0:\n",
    "                raise ValueError(\"Parameter values for parameter ({0}) need \"\n",
    "                                 \"to be a non-empty sequence.\".format(name))\n",
    "                \n",
    "class ParameterGrid:\n",
    "    \"\"\"Grid of parameters with a discrete number of values for each.\n",
    "\n",
    "    Can be used to iterate over parameter value combinations with the\n",
    "    Python built-in function iter.\n",
    "    The order of the generated parameter combinations is deterministic.\n",
    "\n",
    "    Read more in the :ref:`User Guide <grid_search>`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    param_grid : dict of str to sequence, or sequence of such\n",
    "        The parameter grid to explore, as a dictionary mapping estimator\n",
    "        parameters to sequences of allowed values.\n",
    "\n",
    "        An empty dict signifies default parameters.\n",
    "\n",
    "        A sequence of dicts signifies a sequence of grids to search, and is\n",
    "        useful to avoid exploring parameter combinations that make no sense\n",
    "        or have no effect. See the examples below.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.model_selection import ParameterGrid\n",
    "    >>> param_grid = {'a': [1, 2], 'b': [True, False]}\n",
    "    >>> list(ParameterGrid(param_grid)) == (\n",
    "    ...    [{'a': 1, 'b': True}, {'a': 1, 'b': False},\n",
    "    ...     {'a': 2, 'b': True}, {'a': 2, 'b': False}])\n",
    "    True\n",
    "\n",
    "    >>> grid = [{'kernel': ['linear']}, {'kernel': ['rbf'], 'gamma': [1, 10]}]\n",
    "    >>> list(ParameterGrid(grid)) == [{'kernel': 'linear'},\n",
    "    ...                               {'kernel': 'rbf', 'gamma': 1},\n",
    "    ...                               {'kernel': 'rbf', 'gamma': 10}]\n",
    "    True\n",
    "    >>> ParameterGrid(grid)[1] == {'kernel': 'rbf', 'gamma': 1}\n",
    "    True\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    :class:`GridSearchCV`:\n",
    "        Uses :class:`ParameterGrid` to perform a full parallelized parameter\n",
    "        search.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, param_grid):\n",
    "        if not isinstance(param_grid, (Mapping, Iterable)):\n",
    "            raise TypeError('Parameter grid is not a dict or '\n",
    "                            'a list ({!r})'.format(param_grid))\n",
    "\n",
    "        if isinstance(param_grid, Mapping):\n",
    "            # wrap dictionary in a singleton list to support either dict\n",
    "            # or list of dicts\n",
    "            param_grid = [param_grid]\n",
    "\n",
    "        # check if all entries are dictionaries of lists\n",
    "        for grid in param_grid:\n",
    "            if not isinstance(grid, dict):\n",
    "                raise TypeError('Parameter grid is not a '\n",
    "                                'dict ({!r})'.format(grid))\n",
    "            for key in grid:\n",
    "                if not isinstance(grid[key], Iterable):\n",
    "                    raise TypeError('Parameter grid value is not iterable '\n",
    "                                    '(key={!r}, value={!r})'\n",
    "                                    .format(key, grid[key]))\n",
    "\n",
    "        self.param_grid = param_grid\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate over the points in the grid.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        params : iterator over dict of str to any\n",
    "            Yields dictionaries mapping each estimator parameter to one of its\n",
    "            allowed values.\n",
    "        \"\"\"\n",
    "        for p in self.param_grid:\n",
    "            # Always sort the keys of a dictionary, for reproducibility\n",
    "            items = sorted(p.items())\n",
    "            if not items:\n",
    "                yield {}\n",
    "            else:\n",
    "                keys, values = zip(*items)\n",
    "                for v in product(*values):\n",
    "                    params = dict(zip(keys, v))\n",
    "                    yield params\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of points on the grid.\"\"\"\n",
    "        # Product function that can handle iterables (np.product can't).\n",
    "        product = partial(reduce, operator.mul)\n",
    "        return sum(product(len(v) for v in p.values()) if p else 1\n",
    "                   for p in self.param_grid)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        \"\"\"Get the parameters that would be ``ind``th in iteration\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ind : int\n",
    "            The iteration index\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        params : dict of str to any\n",
    "            Equal to list(self)[ind]\n",
    "        \"\"\"\n",
    "        # This is used to make discrete sampling without replacement memory\n",
    "        # efficient.\n",
    "        for sub_grid in self.param_grid:\n",
    "            # XXX: could memoize information used here\n",
    "            if not sub_grid:\n",
    "                if ind == 0:\n",
    "                    return {}\n",
    "                else:\n",
    "                    ind -= 1\n",
    "                    continue\n",
    "\n",
    "            # Reverse so most frequent cycling parameter comes first\n",
    "            keys, values_lists = zip(*sorted(sub_grid.items())[::-1])\n",
    "            sizes = [len(v_list) for v_list in values_lists]\n",
    "            total = np.product(sizes)\n",
    "\n",
    "            if ind >= total:\n",
    "                # Try the next grid\n",
    "                ind -= total\n",
    "            else:\n",
    "                out = {}\n",
    "                for key, v_list, n in zip(keys, values_lists, sizes):\n",
    "                    ind, offset = divmod(ind, n)\n",
    "                    out[key] = v_list[offset]\n",
    "                return out\n",
    "\n",
    "        raise IndexError('ParameterGrid index out of range')\n",
    "\n",
    "\n",
    "class BaseSearchCV(MetaEstimatorMixin, BaseEstimator, metaclass=ABCMeta):\n",
    "    \"\"\"Abstract base class for hyper parameter search with cross-validation.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self, estimator, *, scoring=None, n_jobs=None,\n",
    "                 refit=True, cv=None, verbose=0,\n",
    "                 pre_dispatch='2*n_jobs', error_score=np.nan,\n",
    "                 return_train_score=True):\n",
    "\n",
    "        self.scoring = scoring\n",
    "        self.estimator = estimator\n",
    "        self.n_jobs = n_jobs\n",
    "        self.refit = refit\n",
    "        self.cv = cv\n",
    "        self.verbose = verbose\n",
    "        self.pre_dispatch = pre_dispatch\n",
    "        self.error_score = error_score\n",
    "        self.return_train_score = return_train_score\n",
    "\n",
    "    @property\n",
    "    def _estimator_type(self):\n",
    "        return self.estimator._estimator_type\n",
    "\n",
    "    @property\n",
    "    def _pairwise(self):\n",
    "        # allows cross-validation to see 'precomputed' metrics\n",
    "        return getattr(self.estimator, '_pairwise', False)\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        \"\"\"Returns the score on the given data, if the estimator has been refit.\n",
    "\n",
    "        This uses the score defined by ``scoring`` where provided, and the\n",
    "        ``best_estimator_.score`` method otherwise.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Input data, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "\n",
    "        y : array-like of shape (n_samples, n_output) \\\n",
    "            or (n_samples,), default=None\n",
    "            Target relative to X for classification or regression;\n",
    "            None for unsupervised learning.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('score')\n",
    "        if self.scorer_ is None:\n",
    "            raise ValueError(\"No score function explicitly defined, \"\n",
    "                             \"and the estimator doesn't provide one %s\"\n",
    "                             % self.best_estimator_)\n",
    "        if isinstance(self.scorer_, dict):\n",
    "            if self.multimetric_:\n",
    "                scorer = self.scorer_[self.refit]\n",
    "            else:\n",
    "                scorer = self.scorer_\n",
    "            return scorer(self.best_estimator_, X, y)\n",
    "\n",
    "        # callable\n",
    "        score = self.scorer_(self.best_estimator_, X, y)\n",
    "        if self.multimetric_:\n",
    "            score = score[self.refit]\n",
    "        return score\n",
    "\n",
    "    @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n",
    "    def score_samples(self, X):\n",
    "        \"\"\"Call score_samples on the estimator with the best found parameters.\n",
    "\n",
    "        Only available if ``refit=True`` and the underlying estimator supports\n",
    "        ``score_samples``.\n",
    "\n",
    "        .. versionadded:: 0.24\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : iterable\n",
    "            Data to predict on. Must fulfill input requirements\n",
    "            of the underlying estimator.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_score : ndarray of shape (n_samples,)\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('score_samples')\n",
    "        return self.best_estimator_.score_samples(X)\n",
    "\n",
    "    def _check_is_fitted(self, method_name):\n",
    "        if not self.refit:\n",
    "            raise NotFittedError('This %s instance was initialized '\n",
    "                                 'with refit=False. %s is '\n",
    "                                 'available only after refitting on the best '\n",
    "                                 'parameters. You can refit an estimator '\n",
    "                                 'manually using the ``best_params_`` '\n",
    "                                 'attribute'\n",
    "                                 % (type(self).__name__, method_name))\n",
    "        else:\n",
    "            check_is_fitted(self)\n",
    "\n",
    "    @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n",
    "    def predict(self, X):\n",
    "        \"\"\"Call predict on the estimator with the best found parameters.\n",
    "\n",
    "        Only available if ``refit=True`` and the underlying estimator supports\n",
    "        ``predict``.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : indexable, length n_samples\n",
    "            Must fulfill the input assumptions of the\n",
    "            underlying estimator.\n",
    "\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('predict')\n",
    "        return self.best_estimator_.predict(X)\n",
    "\n",
    "    @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Call predict_proba on the estimator with the best found parameters.\n",
    "\n",
    "        Only available if ``refit=True`` and the underlying estimator supports\n",
    "        ``predict_proba``.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : indexable, length n_samples\n",
    "            Must fulfill the input assumptions of the\n",
    "            underlying estimator.\n",
    "\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('predict_proba')\n",
    "        return self.best_estimator_.predict_proba(X)\n",
    "\n",
    "    @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n",
    "    def predict_log_proba(self, X):\n",
    "        \"\"\"Call predict_log_proba on the estimator with the best found parameters.\n",
    "\n",
    "        Only available if ``refit=True`` and the underlying estimator supports\n",
    "        ``predict_log_proba``.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : indexable, length n_samples\n",
    "            Must fulfill the input assumptions of the\n",
    "            underlying estimator.\n",
    "\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('predict_log_proba')\n",
    "        return self.best_estimator_.predict_log_proba(X)\n",
    "\n",
    "    @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Call decision_function on the estimator with the best found parameters.\n",
    "\n",
    "        Only available if ``refit=True`` and the underlying estimator supports\n",
    "        ``decision_function``.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : indexable, length n_samples\n",
    "            Must fulfill the input assumptions of the\n",
    "            underlying estimator.\n",
    "\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('decision_function')\n",
    "        return self.best_estimator_.decision_function(X)\n",
    "\n",
    "    @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n",
    "    def transform(self, X):\n",
    "        \"\"\"Call transform on the estimator with the best found parameters.\n",
    "\n",
    "        Only available if the underlying estimator supports ``transform`` and\n",
    "        ``refit=True``.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : indexable, length n_samples\n",
    "            Must fulfill the input assumptions of the\n",
    "            underlying estimator.\n",
    "\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('transform')\n",
    "        return self.best_estimator_.transform(X)\n",
    "\n",
    "    @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n",
    "    def inverse_transform(self, Xt):\n",
    "        \"\"\"Call inverse_transform on the estimator with the best found params.\n",
    "\n",
    "        Only available if the underlying estimator implements\n",
    "        ``inverse_transform`` and ``refit=True``.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Xt : indexable, length n_samples\n",
    "            Must fulfill the input assumptions of the\n",
    "            underlying estimator.\n",
    "\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('inverse_transform')\n",
    "        return self.best_estimator_.inverse_transform(Xt)\n",
    "\n",
    "    @property\n",
    "    def n_features_in_(self):\n",
    "        # For consistency with other estimators we raise a AttributeError so\n",
    "        # that hasattr() fails if the search estimator isn't fitted.\n",
    "        try:\n",
    "            check_is_fitted(self)\n",
    "        except NotFittedError as nfe:\n",
    "            raise AttributeError(\n",
    "                \"{} object has no n_features_in_ attribute.\"\n",
    "                .format(self.__class__.__name__)\n",
    "            ) from nfe\n",
    "\n",
    "        return self.best_estimator_.n_features_in_\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        self._check_is_fitted(\"classes_\")\n",
    "        return self.best_estimator_.classes_\n",
    "\n",
    "    def _run_search(self, evaluate_candidates):\n",
    "        \"\"\"Repeatedly calls `evaluate_candidates` to conduct a search.\n",
    "\n",
    "        This method, implemented in sub-classes, makes it possible to\n",
    "        customize the the scheduling of evaluations: GridSearchCV and\n",
    "        RandomizedSearchCV schedule evaluations for their whole parameter\n",
    "        search space at once but other more sequential approaches are also\n",
    "        possible: for instance is possible to iteratively schedule evaluations\n",
    "        for new regions of the parameter search space based on previously\n",
    "        collected evaluation results. This makes it possible to implement\n",
    "        Bayesian optimization or more generally sequential model-based\n",
    "        optimization by deriving from the BaseSearchCV abstract base class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        evaluate_candidates : callable\n",
    "            This callback accepts a list of candidates, where each candidate is\n",
    "            a dict of parameter settings. It returns a dict of all results so\n",
    "            far, formatted like ``cv_results_``.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "\n",
    "        ::\n",
    "\n",
    "            def _run_search(self, evaluate_candidates):\n",
    "                'Try C=0.1 only if C=1 is better than C=10'\n",
    "                all_results = evaluate_candidates([{'C': 1}, {'C': 10}])\n",
    "                score = all_results['mean_test_score']\n",
    "                if score[0] < score[1]:\n",
    "                    evaluate_candidates([{'C': 0.1}])\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"_run_search not implemented.\")\n",
    "\n",
    "    def _check_refit_for_multimetric(self, scores):\n",
    "        \"\"\"Check `refit` is compatible with `scores` is valid\"\"\"\n",
    "        multimetric_refit_msg = (\n",
    "            \"For multi-metric scoring, the parameter refit must be set to a \"\n",
    "            \"scorer key or a callable to refit an estimator with the best \"\n",
    "            \"parameter setting on the whole data and make the best_* \"\n",
    "            \"attributes available for that metric. If this is not needed, \"\n",
    "            f\"refit should be set to False explicitly. {self.refit!r} was \"\n",
    "            \"passed.\")\n",
    "\n",
    "        valid_refit_dict = (isinstance(self.refit, str) and\n",
    "                            self.refit in scores)\n",
    "\n",
    "        if (self.refit is not False and not valid_refit_dict\n",
    "                and not callable(self.refit)):\n",
    "            raise ValueError(multimetric_refit_msg)\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def fit(self, X, y=None, *, groups=None, **fit_params):\n",
    "        \"\"\"Run fit with all sets of parameters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training vector, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "\n",
    "        y : array-like of shape (n_samples, n_output) \\\n",
    "            or (n_samples,), default=None\n",
    "            Target relative to X for classification or regression;\n",
    "            None for unsupervised learning.\n",
    "\n",
    "        groups : array-like of shape (n_samples,), default=None\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
    "            instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
    "\n",
    "        **fit_params : dict of str -> object\n",
    "            Parameters passed to the ``fit`` method of the estimator\n",
    "        \"\"\"\n",
    "        estimator = self.estimator\n",
    "        cv = check_cv(self.cv, y, classifier=is_classifier(estimator))\n",
    "\n",
    "        refit_metric = \"score\"\n",
    "\n",
    "        if callable(self.scoring):\n",
    "            scorers = self.scoring\n",
    "        elif self.scoring is None or isinstance(self.scoring, str):\n",
    "            scorers = check_scoring(self.estimator, self.scoring)\n",
    "        else:\n",
    "            scorers = _check_multimetric_scoring(self.estimator, self.scoring)\n",
    "            self._check_refit_for_multimetric(scorers)\n",
    "            refit_metric = self.refit\n",
    "\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        fit_params = _check_fit_params(X, fit_params)\n",
    "\n",
    "        n_splits = cv.get_n_splits(X, y, groups)\n",
    "\n",
    "        base_estimator = clone(self.estimator)\n",
    "\n",
    "        parallel = Parallel(n_jobs=self.n_jobs,\n",
    "                            pre_dispatch=self.pre_dispatch)\n",
    "\n",
    "        fit_and_score_kwargs = dict(scorer=scorers,\n",
    "                                    fit_params=fit_params,\n",
    "                                    return_train_score=self.return_train_score,\n",
    "                                    return_n_test_samples=True,\n",
    "                                    return_times=True,\n",
    "                                    return_parameters=False,\n",
    "                                    error_score=self.error_score,\n",
    "                                    verbose=self.verbose)\n",
    "        results = {}\n",
    "        with parallel:\n",
    "            all_candidate_params = []\n",
    "            all_out = []\n",
    "\n",
    "            def evaluate_candidates(candidate_params):\n",
    "                candidate_params = list(candidate_params)\n",
    "                n_candidates = len(candidate_params)\n",
    "\n",
    "                if self.verbose > 0:\n",
    "                    print(\"Fitting {0} folds for each of {1} candidates,\"\n",
    "                          \" totalling {2} fits\".format(\n",
    "                              n_splits, n_candidates, n_candidates * n_splits))\n",
    "\n",
    "                out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n",
    "                                                       X, y,\n",
    "                                                       train=train, test=test,\n",
    "                                                       parameters=parameters,\n",
    "                                                       split_progress=(\n",
    "                                                           split_idx,\n",
    "                                                           n_splits),\n",
    "                                                       candidate_progress=(\n",
    "                                                           cand_idx,\n",
    "                                                           n_candidates),\n",
    "                                                       **fit_and_score_kwargs)\n",
    "                               for (cand_idx, parameters),\n",
    "                                   (split_idx, (train, test)) in product(\n",
    "                                   enumerate(candidate_params),\n",
    "                                   enumerate(cv.split(X, y, groups))))\n",
    "\n",
    "                if len(out) < 1:\n",
    "                    raise ValueError('No fits were performed. '\n",
    "                                     'Was the CV iterator empty? '\n",
    "                                     'Were there no candidates?')\n",
    "                elif len(out) != n_candidates * n_splits:\n",
    "                    raise ValueError('cv.split and cv.get_n_splits returned '\n",
    "                                     'inconsistent results. Expected {} '\n",
    "                                     'splits, got {}'\n",
    "                                     .format(n_splits,\n",
    "                                             len(out) // n_candidates))\n",
    "\n",
    "                # For callable self.scoring, the return type is only know after\n",
    "                # calling. If the return type is a dictionary, the error scores\n",
    "                # can now be inserted with the correct key. The type checking\n",
    "                # of out will be done in `_insert_error_scores`.\n",
    "                if callable(self.scoring):\n",
    "                    _insert_error_scores(out, self.error_score)\n",
    "                all_candidate_params.extend(candidate_params)\n",
    "                all_out.extend(out)\n",
    "\n",
    "                nonlocal results\n",
    "                results = self._format_results(\n",
    "                    all_candidate_params, n_splits, all_out)\n",
    "                return results\n",
    "\n",
    "            self._run_search(evaluate_candidates)\n",
    "\n",
    "            # multimetric is determined here because in the case of a callable\n",
    "            # self.scoring the return type is only known after calling\n",
    "            first_test_score = all_out[0]['test_scores']\n",
    "            self.multimetric_ = isinstance(first_test_score, dict)\n",
    "\n",
    "            # check refit_metric now for a callabe scorer that is multimetric\n",
    "            if callable(self.scoring) and self.multimetric_:\n",
    "                self._check_refit_for_multimetric(first_test_score)\n",
    "                refit_metric = self.refit\n",
    "\n",
    "        # For multi-metric evaluation, store the best_index_, best_params_ and\n",
    "        # best_score_ iff refit is one of the scorer names\n",
    "        # In single metric evaluation, refit_metric is \"score\"\n",
    "        if self.refit or not self.multimetric_:\n",
    "            # If callable, refit is expected to return the index of the best\n",
    "            # parameter set.\n",
    "            if callable(self.refit):\n",
    "                self.best_index_ = self.refit(results)\n",
    "                if not isinstance(self.best_index_, numbers.Integral):\n",
    "                    raise TypeError('best_index_ returned is not an integer')\n",
    "                if (self.best_index_ < 0 or\n",
    "                   self.best_index_ >= len(results[\"params\"])):\n",
    "                    raise IndexError('best_index_ index out of range')\n",
    "            else:\n",
    "                self.best_index_ = results[\"rank_test_%s\"\n",
    "                                           % refit_metric].argmin()\n",
    "                self.best_score_ = results[\"mean_test_%s\" % refit_metric][\n",
    "                                           self.best_index_]\n",
    "            self.best_params_ = results[\"params\"][self.best_index_]\n",
    "\n",
    "        if self.refit:\n",
    "            # we clone again after setting params in case some\n",
    "            # of the params are estimators as well.\n",
    "            self.best_estimator_ = clone(clone(base_estimator).set_params(\n",
    "                **self.best_params_))\n",
    "            refit_start_time = time.time()\n",
    "            if y is not None:\n",
    "                self.best_estimator_.fit(X, y, **fit_params)\n",
    "            else:\n",
    "                self.best_estimator_.fit(X, **fit_params)\n",
    "            refit_end_time = time.time()\n",
    "            self.refit_time_ = refit_end_time - refit_start_time\n",
    "\n",
    "        # Store the only scorer not as a dict for single metric evaluation\n",
    "        self.scorer_ = scorers\n",
    "\n",
    "        self.cv_results_ = results\n",
    "        self.n_splits_ = n_splits\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _format_results(self, candidate_params, n_splits, out):\n",
    "        n_candidates = len(candidate_params)\n",
    "        out = _aggregate_score_dicts(out)\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        def _store(key_name, array, weights=None, splits=False, rank=False):\n",
    "            \"\"\"A small helper to store the scores/times to the cv_results_\"\"\"\n",
    "            # When iterated first by splits, then by parameters\n",
    "            # We want `array` to have `n_candidates` rows and `n_splits` cols.\n",
    "            array = np.array(array, dtype=np.float64).reshape(n_candidates,\n",
    "                                                              n_splits)\n",
    "            if splits:\n",
    "                for split_idx in range(n_splits):\n",
    "                    # Uses closure to alter the results\n",
    "                    results[\"split%d_%s\"\n",
    "                            % (split_idx, key_name)] = array[:, split_idx]\n",
    "\n",
    "            array_means = np.average(array, axis=1, weights=weights)\n",
    "            results['mean_%s' % key_name] = array_means\n",
    "\n",
    "            if (key_name.startswith((\"train_\", \"test_\")) and\n",
    "                    np.any(~np.isfinite(array_means))):\n",
    "                warnings.warn(\n",
    "                    f\"One or more of the {key_name.split('_')[0]} scores \"\n",
    "                    f\"are non-finite: {array_means}\",\n",
    "                    category=UserWarning\n",
    "                )\n",
    "\n",
    "            # Weighted std is not directly available in numpy\n",
    "            array_stds = np.sqrt(np.average((array -\n",
    "                                             array_means[:, np.newaxis]) ** 2,\n",
    "                                            axis=1, weights=weights))\n",
    "            results['std_%s' % key_name] = array_stds\n",
    "\n",
    "            if rank:\n",
    "                results[\"rank_%s\" % key_name] = np.asarray(\n",
    "                    rankdata(-array_means, method='min'), dtype=np.int32)\n",
    "\n",
    "        _store('fit_time', out[\"fit_time\"])\n",
    "        _store('score_time', out[\"score_time\"])\n",
    "        # Use one MaskedArray and mask all the places where the param is not\n",
    "        # applicable for that candidate. Use defaultdict as each candidate may\n",
    "        # not contain all the params\n",
    "        param_results = defaultdict(partial(MaskedArray,\n",
    "                                            np.empty(n_candidates,),\n",
    "                                            mask=True,\n",
    "                                            dtype=object))\n",
    "        for cand_idx, params in enumerate(candidate_params):\n",
    "            for name, value in params.items():\n",
    "                # An all masked empty array gets created for the key\n",
    "                # `\"param_%s\" % name` at the first occurrence of `name`.\n",
    "                # Setting the value at an index also unmasks that index\n",
    "                param_results[\"param_%s\" % name][cand_idx] = value\n",
    "\n",
    "        results.update(param_results)\n",
    "        # Store a list of param dicts at the key 'params'\n",
    "        results['params'] = candidate_params\n",
    "\n",
    "        test_scores_dict = _normalize_score_results(out[\"test_scores\"])\n",
    "        if self.return_train_score:\n",
    "            train_scores_dict = _normalize_score_results(out[\"train_scores\"])\n",
    "\n",
    "        for scorer_name in test_scores_dict:\n",
    "            # Computed the (weighted) mean and std for test scores alone\n",
    "            _store('test_%s' % scorer_name, test_scores_dict[scorer_name],\n",
    "                   splits=True, rank=True,\n",
    "                   weights=None)\n",
    "            if self.return_train_score:\n",
    "                _store('train_%s' % scorer_name,\n",
    "                       train_scores_dict[scorer_name],\n",
    "                       splits=True)\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "class GridSearchCV(BaseSearchCV):\n",
    "\n",
    "    _required_parameters = [\"estimator\", \"param_grid\"]\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self, estimator, param_grid, *, scoring=None,\n",
    "                 n_jobs=None, refit=True, cv=None,\n",
    "                 verbose=0, pre_dispatch='2*n_jobs',\n",
    "                 error_score=np.nan, return_train_score=False):\n",
    "        super().__init__(\n",
    "            estimator=estimator, scoring=scoring,\n",
    "            n_jobs=n_jobs, refit=refit, cv=cv, verbose=verbose,\n",
    "            pre_dispatch=pre_dispatch, error_score=error_score,\n",
    "            return_train_score=return_train_score)\n",
    "        self.param_grid = param_grid\n",
    "        _check_param_grid(param_grid)\n",
    "\n",
    "    def _run_search(self, evaluate_candidates):\n",
    "        \"\"\"Search all candidates in param_grid\"\"\"\n",
    "        evaluate_candidates(ParameterGrid(self.param_grid))\n",
    "        \n",
    "def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n",
    "                   parameters, fit_params, return_train_score=False,\n",
    "                   return_parameters=False, return_n_test_samples=False,\n",
    "                   return_times=False, return_estimator=False,\n",
    "                   split_progress=None, candidate_progress=None,\n",
    "                   error_score=np.nan):\n",
    "\n",
    "    \"\"\"Fit estimator and compute scores for a given dataset split\"\"\"\n",
    "    progress_msg = \"\"\n",
    "    if verbose > 2:\n",
    "        if split_progress is not None:\n",
    "            progress_msg = f\" {split_progress[0]+1}/{split_progress[1]}\"\n",
    "        if candidate_progress and verbose > 9:\n",
    "            progress_msg += (f\"; {candidate_progress[0]+1}/\"\n",
    "                             f\"{candidate_progress[1]}\")\n",
    "\n",
    "    if verbose > 1:\n",
    "        if parameters is None:\n",
    "            params_msg = ''\n",
    "        else:\n",
    "            sorted_keys = sorted(parameters)  # Ensure deterministic o/p\n",
    "            params_msg = (', '.join(f'{k}={parameters[k]}'\n",
    "                                    for k in sorted_keys))\n",
    "    if verbose > 9:\n",
    "        start_msg = f\"[CV{progress_msg}] START {params_msg}\"\n",
    "        print(f\"{start_msg}{(80 - len(start_msg)) * '.'}\")\n",
    "\n",
    "    # Adjust length of sample weights\n",
    "    fit_params = fit_params if fit_params is not None else {}\n",
    "    fit_params = _check_fit_params(X, fit_params, train)\n",
    "\n",
    "    if parameters is not None:\n",
    "        # clone after setting parameters in case any parameters\n",
    "        # are estimators (like pipeline steps)\n",
    "        # because pipeline doesn't clone steps in fit\n",
    "        cloned_parameters = {}\n",
    "        for k, v in parameters.items():\n",
    "            cloned_parameters[k] = clone(v, safe=False)\n",
    "\n",
    "        estimator = estimator.set_params(**cloned_parameters)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    X_train_before, y_train = _safe_split(estimator, X, y, train)\n",
    "    X_test_before, y_test = _safe_split(estimator, X, y, test, train)\n",
    "    \n",
    "    # Adjust features such that there is no data leakage across the k-folds\n",
    "    X_train, remnant_dict, all_dict, remnant_dict_hard, all_dict_hard, \\\n",
    "          = insert_local_remnant_ratios(\n",
    "        X_train_before,y_train)\n",
    "    X_test = insert_local_test_ratios(X_test_before, remnant_dict, all_dict, \\\n",
    "                                        remnant_dict_hard, all_dict_hard)\n",
    "\n",
    "    \n",
    "    \n",
    "    result = {}\n",
    "    try:\n",
    "        if y_train is None:\n",
    "            estimator.fit(X_train, **fit_params)\n",
    "        else:\n",
    "            estimator.fit(X_train, y_train, **fit_params)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Note fit time as time until error\n",
    "        fit_time = time.time() - start_time\n",
    "        score_time = 0.0\n",
    "        if error_score == 'raise':\n",
    "            raise\n",
    "        elif isinstance(error_score, numbers.Number):\n",
    "            if isinstance(scorer, dict):\n",
    "                test_scores = {name: error_score for name in scorer}\n",
    "                if return_train_score:\n",
    "                    train_scores = test_scores.copy()\n",
    "            else:\n",
    "                test_scores = error_score\n",
    "                if return_train_score:\n",
    "                    train_scores = error_score\n",
    "            warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
    "                          \" partition for these parameters will be set to %f. \"\n",
    "                          \"Details: \\n%s\" %\n",
    "                          (error_score, format_exc()),\n",
    "                          FitFailedWarning)\n",
    "        else:\n",
    "            raise ValueError(\"error_score must be the string 'raise' or a\"\n",
    "                             \" numeric value. (Hint: if using 'raise', please\"\n",
    "                             \" make sure that it has been spelled correctly.)\")\n",
    "        result[\"fit_failed\"] = True\n",
    "    else:\n",
    "        result[\"fit_failed\"] = False\n",
    "\n",
    "        fit_time = time.time() - start_time\n",
    "        test_scores = _score(estimator, X_test, y_test, scorer)\n",
    "        score_time = time.time() - start_time - fit_time\n",
    "        if return_train_score:\n",
    "            train_scores = _score(estimator, X_train, y_train, scorer)\n",
    "\n",
    "    if verbose > 1:\n",
    "        total_time = score_time + fit_time\n",
    "        end_msg = f\"[CV{progress_msg}] END \"\n",
    "        result_msg = params_msg + (\";\" if params_msg else \"\")\n",
    "        if verbose > 2 and isinstance(test_scores, dict):\n",
    "            for scorer_name in sorted(test_scores):\n",
    "                result_msg += f\" {scorer_name}: (\"\n",
    "                if return_train_score:\n",
    "                    scorer_scores = train_scores[scorer_name]\n",
    "                    result_msg += f\"train={scorer_scores:.3f}, \"\n",
    "                result_msg += f\"test={test_scores[scorer_name]:.3f})\"\n",
    "        result_msg += f\" total time={logger.short_format_time(total_time)}\"\n",
    "\n",
    "        # Right align the result_msg\n",
    "        end_msg += \".\" * (80 - len(end_msg) - len(result_msg))\n",
    "        end_msg += result_msg\n",
    "        print(end_msg)\n",
    "\n",
    "    result[\"test_scores\"] = test_scores\n",
    "    if return_train_score:\n",
    "        result[\"train_scores\"] = train_scores\n",
    "    if return_n_test_samples:\n",
    "        result[\"n_test_samples\"] = _num_samples(X_test)\n",
    "    if return_times:\n",
    "        result[\"fit_time\"] = fit_time\n",
    "        result[\"score_time\"] = score_time\n",
    "    if return_parameters:\n",
    "        result[\"parameters\"] = parameters\n",
    "    if return_estimator:\n",
    "        result[\"estimator\"] = estimator\n",
    "    return result\n",
    "\n",
    "def _score(estimator, X_test, y_test, scorer):\n",
    "    \"\"\"Compute the score(s) of an estimator on a given test set.\n",
    "\n",
    "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
    "    float is returned.\n",
    "    \"\"\"\n",
    "    if isinstance(scorer, dict):\n",
    "        # will cache method calls if needed. scorer() returns a dict\n",
    "        scorer = _MultimetricScorer(**scorer)\n",
    "    if y_test is None:\n",
    "        scores = scorer(estimator, X_test)\n",
    "    else:\n",
    "        scores = scorer(estimator, X_test, y_test)\n",
    "\n",
    "    error_msg = (\"scoring must return a number, got %s (%s) \"\n",
    "                 \"instead. (scorer=%s)\")\n",
    "    if isinstance(scores, dict):\n",
    "        for name, score in scores.items():\n",
    "            if hasattr(score, 'item'):\n",
    "                with suppress(ValueError):\n",
    "                    # e.g. unwrap memmapped scalars\n",
    "                    score = score.item()\n",
    "            if not isinstance(score, numbers.Number):\n",
    "                raise ValueError(error_msg % (score, type(score), name))\n",
    "            scores[name] = score\n",
    "    else:  # scalar\n",
    "        if hasattr(scores, 'item'):\n",
    "            with suppress(ValueError):\n",
    "                # e.g. unwrap memmapped scalars\n",
    "                scores = scores.item()\n",
    "        if not isinstance(scores, numbers.Number):\n",
    "            raise ValueError(error_msg % (scores, type(scores), scorer))\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97fd047",
   "metadata": {},
   "source": [
    "# Create LoTSS-DR2 cutouts of 151 remnants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49371d0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create LOTSS cutout sets\n",
    "# Get cutout size in pixels\n",
    "rotated_size_arcsec = 100\n",
    "rotated_size = int(round(rotated_size_arcsec/angular_resolution_LoTSS))\n",
    "fullsize = int(np.ceil(rotated_size*np.sqrt(2)))\n",
    "print(f'Full cutout sizes will be {fullsize} pixels or {fullsize*angular_resolution_LoTSS} arcsec')\n",
    "print(f'Rotated cutout sizes will be {rotated_size} pixels or {rotated_size_arcsec} arcsec')\n",
    "LoTSS_DR2_dir='LoTSS_DR2/RA0h_field'\n",
    "\n",
    "\n",
    "overwrite=False\n",
    "s4 = CutoutSettings(experiment='LoTSS only; no clip; size invariant', \n",
    "            run_id=312, store_filename='LoTSSDR2_151remnants_noclip_sizeinvariant', \n",
    "            fullsize=fullsize, data_dir=LoTSS_DR2_dir,arcsec_per_pixel=angular_resolution_LoTSS, \n",
    "            overwrite=overwrite, apply_clipping=False, lower_sigma_limit=1.5,\n",
    "            upper_sigma_limit=1e9, variable_size=True,\n",
    "            map_to_run_id=314, \n",
    "            normalize=False,zoom_in=False,\n",
    "            map_to_binpath='LoTSS_Lockman_sizeinvariant_resolved_10mJy_noclip_9x9_ID314/resultLoTSS_Lockman_sizeinvariant_resolved_10mJy_noclip_9x9x95_0.32305409446133365_0.0030974898406490115_ID314.bin')\n",
    "s = s4\n",
    "debug = False\n",
    "np.random.seed(42)\n",
    "with open(os.path.join(run_dir,'map_151remnants_to_lockman_LoTSDR2.sh'),'w') as f:\n",
    "    \n",
    "    # Define parameters\n",
    "    cutouts_bin_name = s.store_filename\n",
    "    #cutouts_binary_path\n",
    "    run_id = s.run_id\n",
    "    gpu_id = 0\n",
    "    som_size = 2\n",
    "    overwrite=s.overwrite\n",
    "    # Create SOM info object\n",
    "    som = post.SOM([], number_of_channels, som_size, som_size, som_depth, \"quadratic\", \n",
    "               output_directory, trained_subdirectory, som_label, rotated_size, run_id)\n",
    "    som.som_width = 9\n",
    "    som.som_height = 9\n",
    "    som.som_depth = 1\n",
    "    som.number_of_channels = 1\n",
    "    som.gauss_decrease = 0.9\n",
    "    som.gauss_end = 0.3\n",
    "    som.learning_constraint_decrease = 0.8\n",
    "    som.learning_constraint = som.som_width*som.som_height/100\n",
    "    som.gauss_start = max(som.som_width, som.som_height)/2\n",
    "    som.random_seed = 42\n",
    "    som.pbc = False\n",
    "    som.init = \"zero\"\n",
    "    som.layout = \"quadratic\"\n",
    "    som.training_dataset_name = cutouts_bin_name\n",
    "    som.save()\n",
    "    som.print()\n",
    "    rotated_size = int(round(rotated_size_arcsec/angular_resolution_LoTSS))\n",
    "    fullsize = int(np.ceil(rotated_size*np.sqrt(2)))\n",
    "\n",
    "    # Get numpy list of cutouts and update catalogue to only contain sources that succesfully got extracted.\n",
    "    store_filename = cutouts_bin_name\n",
    "    lower_sigma_limit = s.lower_sigma_limit\n",
    "    upper_sigma_limit = s.upper_sigma_limit\n",
    "    calibration_cutouts, calibration_cat_extracted = post.fits_to_cutouts_using_astropy(\n",
    "        fits_filename, s.store_filename, \n",
    "        s.fullsize, calibration_set, mosaic_id_key, ra_key, dec_key, s.data_dir, \n",
    "        arcsec_per_pixel=s.arcsec_per_pixel,\n",
    "        single_field=False,\n",
    "        gaus_cat=gaul_cat, remove_neighbours=True,component_cat=comp_cat,\n",
    "        rely_on_catalogue_size=True,sort=False, dimensions_normal=True, \n",
    "        overwrite=s.overwrite, \n",
    "        apply_clipping=s.apply_clipping, lower_sigma_limit=s.lower_sigma_limit,\n",
    "        upper_sigma_limit=s.upper_sigma_limit, rescale=True,\n",
    "        variable_size=s.variable_size, destination_size=s.fullsize, \n",
    "        rough_remove_neighbours=False, full_cat = value_added_catalogue,\n",
    "        get_local_rms=True,\n",
    "        apply_mask=True, verbose=False, mode='partial')    \n",
    "\n",
    "    # Plot a random subset of the data\n",
    "    if debug:\n",
    "        for i in range(5):\n",
    "            if 1==1 or not s.apply_clipping:\n",
    "                print('RA DEC and totalflux, and peakflux')\n",
    "                print(calibration_cat_extracted.iloc[i].RA, calibration_cat_extracted.iloc[i].DEC)\n",
    "                print(calibration_cat_extracted.iloc[i].Total_flux, calibration_cat_extracted.iloc[i].Peak_flux)\n",
    "                print('LoTSs')\n",
    "                post.plot_cutout2D(calibration_cutouts[i], \n",
    "                                            wcs=None, sqrt=True,colorbar=True,cmap='viridis')\n",
    "\n",
    "    # Check cutouts shape\n",
    "    print(\"Cutouts shape (# cutouts, # channels, width, height) = \", np.shape(calibration_cutouts))\n",
    "    # Write cutouts to binary file (required file format for PINK software)\n",
    "    cutouts_binary_path_lotss = os.path.join(data_directory, cutouts_bin_name + '.bin')\n",
    "    post.write_numpy_to_binary_v2(cutouts_binary_path_lotss, calibration_cutouts, \n",
    "                                    som.layout, overwrite=True)\n",
    "\n",
    "    # Write mapping bash scripts\n",
    "    map_path = os.path.join(map_dir, \n",
    "                f'{cutouts_bin_name}_ID{s.run_id}_mapped_to_ID{s.map_to_run_id}.bin')\n",
    "    s.map_path = map_path\n",
    "    s.som = som\n",
    "    s.save(output_directory)\n",
    "    mapstring =post.map_dataset_to_trained_som(som, cutouts_binary_path_lotss, \n",
    "                map_path, s.map_to_binpath,\n",
    "        gpu_id, use_gpu=True, verbose=True, version=2,\n",
    "        alternate_neuron_dimension=None, use_cuda_visible_devices=True,\n",
    "        rotation_path=None, circular_shape=False)\n",
    "    print(mapstring, file=f)\n",
    "    print(\"Number of extracted large cutouts:\", len(calibration_cutouts))\n",
    "    print(\"Bash script to map to SOM:\", map_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470aed72",
   "metadata": {},
   "source": [
    "# Discard potential nearby SFGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d0bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All not calibration sources\n",
    "run_id=312\n",
    "settingsfile = post.load_pickle(os.path.join(output_directory,\n",
    "                                f'SOM_settings_object_id{run_id}.pkl'))\n",
    "run_id=367\n",
    "cali_SFGfiltered_settingsfile = deepcopy(settingsfile)\n",
    "cali_SFGfiltered_settingsfile.run_id = run_id\n",
    "cali_SFGfiltered_settingsfile.store_filename = \\\n",
    "f'LoTSSDR2_{len(calibration_cutouts)}remnants_noclip_sizeinvariant_SFGfiltered'\n",
    "\n",
    "# Get all HETDEX sources > 60 that were successfully extracted\n",
    "run_id=318\n",
    "settingsfile = post.load_pickle(os.path.join(output_directory,\n",
    "                                f'SOM_settings_object_id{run_id}.pkl'))\n",
    "\n",
    "run_id=340\n",
    "hetdex_SFGfiltered_settingsfile = deepcopy(settingsfile)\n",
    "hetdex_SFGfiltered_settingsfile.run_id = run_id\n",
    "hetdex_SFGfiltered_settingsfile.store_filename += '_SFGfiltered' \n",
    "\n",
    "# Load catalogue\n",
    "cat_path = os.path.join(output_directory,'catalogue_'+ \\\n",
    "    settingsfile.store_filename +'.h5')\n",
    "cat_hetdex_bigger_than60arcsec_extracted = pd.read_hdf(cat_path)\n",
    "extraction_fail_count = len(hetdex_bigger_than60arcsec)-len(cat_hetdex_bigger_than60arcsec_extracted)\n",
    "print(f\"Initial value-added catalogue contains {len(hetdex_bigger_than60arcsec)} sources \"\n",
    "     f\"bigger than 60arcsec.\\n\"\n",
    "     f\"We cannot create cutouts for {extraction_fail_count} sources, \"\n",
    "      f\"leaving us with {len(cat_hetdex_bigger_than60arcsec_extracted)} sources.\")\n",
    "# Load cutouts\n",
    "cutouts_path = os.path.join(output_directory,\n",
    "    settingsfile.store_filename +'.npy')\n",
    "print(\"Loading cutouts from:\",cutouts_path )\n",
    "cutouts_hetdex_bigger_than60arcsec_extracted = np.load(cutouts_path)\n",
    "print(f\"Of these {len(cutouts_hetdex_bigger_than60arcsec_extracted)} cutouts:\")\n",
    "print(f\"{len(calibration_cutouts)} have been accepted as AGN remnant candidate through visual inspection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80744bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter based on nearby SFG (starforming galaxies)\n",
    "print(\"For the calibration set:\")\n",
    "accepted_ids_cali, rejected_ids_cali = post.filter_cutouts_with_galaxy_scale_emission(\n",
    "    list(range(len(calibration_cat_extracted))), calibration_cat_extracted,\n",
    "   radio_to_optical_extent_ratio=10, object_search_radius_in_arcsec=10, verbose=True)\n",
    "assert len(rejected_ids_cali)==0, \"calibration set should not contain sfg\"\n",
    "\n",
    "print(\"\\nFor the notcalibration set:\")\n",
    "accepted_ids_notcali, rejected_ids_notcali = post.filter_cutouts_with_galaxy_scale_emission(\n",
    "    list(range(len(notcalibration_cat_extracted))), notcalibration_cat_extracted,\n",
    "   radio_to_optical_extent_ratio=10, object_search_radius_in_arcsec=10, verbose=False)\n",
    "print(f'{len(rejected_ids_notcali)} out of {len(notcalibration_cat_extracted)} sources were '\n",
    "      'rejected because the angular extent of the optical emission is larger than '\n",
    "      '10 times the extend of the radio emission.')\n",
    "\n",
    "\n",
    "accepted_ids, rejected_ids = post.filter_cutouts_with_galaxy_scale_emission(\n",
    "    list(range(len(cat_hetdex_bigger_than60arcsec_extracted))), \n",
    "    cat_hetdex_bigger_than60arcsec_extracted,\n",
    "   radio_to_optical_extent_ratio=10, object_search_radius_in_arcsec=10, verbose=False)\n",
    "print(\"\\nFor all HETDEX sources >60arcsec:\")\n",
    "print(f'{len(rejected_ids)} out of {len(cat_hetdex_bigger_than60arcsec_extracted)} sources were '\n",
    "      'rejected because the angular extent of the optical emission is larger than '\n",
    "      '10 times the extend of the radio emission.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ce536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tally how many filtered sources are actually SFG\n",
    "debug=False\n",
    "if debug:\n",
    "    bin_path =  os.path.join(data_directory,\n",
    "                        settingsfile.store_filename +'.bin')\n",
    "    post.plot_LoTSS_and_PANSTARRS(1000, rejected_ids, \n",
    "            cat_hetdex_bigger_than60arcsec_extracted, bin_path, \n",
    "        version=2, save=False,         \n",
    "         save_dir=None, save_index=None, query_SIMBAD_for_source_description=False,\n",
    "            overwrite=False, \n",
    "         print_radio_to_optical_extent=False,\n",
    "        title_lotss='LoTSS DR2',\n",
    "         print_FIRST_cat_message=False,model_maj_min_angle_degree=False,                            \n",
    "         arcsec_per_pixel_lotss=1.5, arcsec_per_pixel_PANSTARRS=0.25, plot_reticle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61739d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new files after filtering\n",
    "# cali\n",
    "cali_SFGfiltered_settingsfile, cali_SFGfiltered_cat, cali_SFGfiltered_cat_path, \\\n",
    "    cali_SFGfiltered_cutouts, cali_SFGfiltered_cutouts_path, \\\n",
    "    cali_SFGfiltered_bin_path = post.create_new_files_after_filtering(\n",
    "    accepted_ids_cali, calibration_cutouts,\n",
    "    calibration_cat_extracted, cali_SFGfiltered_settingsfile,\n",
    "    data_directory,output_directory)\n",
    "# all >60\"\n",
    "hetdex_SFGfiltered_settingsfile, hetdex_SFGfiltered_cat, hetdex_SFGfiltered_cat_path, \\\n",
    "    hetdex_SFGfiltered_cutouts, hetdex_SFGfiltered_cutouts_path, \\\n",
    "    hetdex_SFGfiltered_bin_path = post.create_new_files_after_filtering(\n",
    "    accepted_ids,cutouts_hetdex_bigger_than60arcsec_extracted,\n",
    "    cat_hetdex_bigger_than60arcsec_extracted,hetdex_SFGfiltered_settingsfile,\n",
    "    data_directory,output_directory)\n",
    "\n",
    "print(f\"\\n So we have {len(hetdex_SFGfiltered_cutouts)} hetdex cutouts:\")\n",
    "print(f\"{len(cali_SFGfiltered_cutouts)} have been accepted as AGN remnant candidate through visual inspection.\")\n",
    "print(f\"and {len(notcali_SFGfiltered_cutouts)} have been rejected as AGN remnant candidate through visual inspection.\")\n",
    "print(f\"So {len(notcali_SFGfiltered_cutouts)+len(cali_SFGfiltered_cutouts)} visually inspected sources left.\")\n",
    "#print(f\"{len(hetdex_bigger_than60arcsec)-151-extraction_fail_count+1} non remnant after extraction and 150 remnants.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da39ef9",
   "metadata": {},
   "source": [
    "#  Split data into train and test (hold-out) set\n",
    "And bring down class imbalance by undersampling the non-candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f06c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "source_names = hetdex_SFGfiltered_cat.Source_Name.values\n",
    "labels = np.array([sn in cali_SFGfiltered_cat.Source_Name.values\n",
    " for sn in source_names])\n",
    "\n",
    "def undersample_non_candidates_upto(labels,upto=1050,random_seed=42):\n",
    "    \"\"\"Explicitly undersample a class upto\"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    # Get indices of non candidates\n",
    "    idx_list = np.array(deepcopy([ilabel for ilabel, label in enumerate(labels) if label==False]))\n",
    "    rest_list = np.array(deepcopy([ilabel for ilabel, label in enumerate(labels) if label]))\n",
    "    if upto>=len(idx_list):\n",
    "        print(\"You are asking to oversample this class.\")\n",
    "        sdfdsf\n",
    "    # Random shuffle a copy of these indices\n",
    "    np.random.shuffle(idx_list)\n",
    "    # Get the first upto indices from this list\n",
    "    idx_list = sorted(np.concatenate([idx_list[:upto],rest_list]))\n",
    "    return idx_list\n",
    "    \n",
    "np.random.seed(random_seed)\n",
    "# Split data into train and test set\n",
    "test_size=0.3\n",
    "idx_train, idx_test = train_test_split(list(range(len(labels))), test_size=test_size,\n",
    "            stratify=labels, random_state=random_seed)\n",
    "\n",
    "cat_train = hetdex_SFGfiltered_cat.iloc[idx_train]\n",
    "cat_test = hetdex_SFGfiltered_cat.iloc[idx_test]\n",
    "labels_train_full = labels[idx_train]\n",
    "labels_test = labels[idx_test]\n",
    "source_names_train = source_names[idx_train]\n",
    "source_names_test = source_names[idx_test]\n",
    "hetdex_cutouts_train = hetdex_SFGfiltered_cutouts[idx_train]\n",
    "cutouts_test = hetdex_SFGfiltered_cutouts[idx_test]\n",
    "\n",
    "undersampled_train_ids = undersample_non_candidates_upto(labels_train_full,\n",
    "                                 upto=int(10*np.sum(labels_train_full)),\n",
    "                                 random_seed=random_seed)\n",
    "\n",
    "undersampled_train_ids_cali = np.array([tid\n",
    " for tid in undersampled_train_ids if labels_train_full[tid]])\n",
    "idx_test_cali = np.array([tid\n",
    " for tid in idx_test if labels[tid]])\n",
    "labels_train = labels_train_full[undersampled_train_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec160bdd",
   "metadata": {},
   "source": [
    "# Numbers for approach diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data into single pandas DF for convenient seaborn plotting\n",
    "plot_data1 = pd.DataFrame({'source_size':np.log10(hetdex_SFGfiltered_cat[\"source_size\"]),\n",
    "            'Total_flux':np.log10(hetdex_SFGfiltered_cat[\"Total_flux\"]),\n",
    "            'Dataset':['All sources >60arcsec' for _ in range(len(hetdex_SFGfiltered_cat))]})\n",
    "plot_data2 = pd.DataFrame({'source_size':np.log10(cali_SFGfiltered_cat[\"source_size\"]),\n",
    "            'Total_flux':np.log10(cali_SFGfiltered_cat[\"Total_flux\"]),\n",
    "            'Dataset':['Calibration sources' for _ in range(len(cali_SFGfiltered_cat))]})\n",
    "plot_data = pd.concat([plot_data1,plot_data2])\n",
    "\n",
    "# Seaborn plot\n",
    "g = sns.JointGrid(data=plot_data, x='source_size', \n",
    "                  y=\"Total_flux\", hue='Dataset', marginal_ticks=True)\n",
    "g.plot_joint(sns.scatterplot,legend=False,size=1)\n",
    "#g.plot_marginals(sns.kdeplot,common_norm=False)\n",
    "g.plot_marginals(sns.histplot,stat='density',common_norm=False,element='step',fill=True)\n",
    "g.set_axis_labels('Major axis length log10[arcsec]','Total flux log10[mJy]')\n",
    "plt.savefig(os.path.join(paper_fig_dir,\n",
    "        \"sourcesize_vs_totalflux.pdf\"),\n",
    "           bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{np.sum(value_added_catalogue['source_size'] > 60)} sources in hetdex are >60arcsec,\"\n",
    "     f\" of which {len(remnant_names)} are remnant candidates.\")\n",
    "print(f\"Cutout extraction succeeds for {len(cat_hetdex_bigger_than60arcsec_extracted)}\"\n",
    "      f\" sources in hetdex >60arcsec of which {len(calibration_cat_extracted)} remnant candidates.\")\n",
    "print(f\"After excluding nearby SFGs we have {len(hetdex_SFGfiltered_cutouts)} sources left\"\n",
    "      f\" of which {len(cali_SFGfiltered_cutouts)} are remnant candidates.\")\n",
    "print(f\"\"\"\\nAfter visual inspection comparing the LoTSS and the Panoramic Survey Telescope \n",
    "and Rapid Response System 1 (Pan-STARRS1) $3\\\\pi$ steradian survey \\\\citep{{panstarrs}} images,\n",
    "we found that this label turns out to be correct for ${(len(rejected_ids)-23)/len(rejected_ids)*100:.1f}\\\\%$ \n",
    "(${(len(rejected_ids)-23)}/{len(rejected_ids)}$) of these sources.\n",
    "When classifying radio sources as AGN remnant candidates in even larger datasets in the \n",
    "future, we will not visually inspect these potential nearby SFGs but simply discard them.\n",
    "In this work too, we discard all ${len(rejected_ids)}$ sources labelled as potential \n",
    "nearby SFGs, leaving us with $3,908$ radio sources of which $150$ candidates.\n",
    "This means that we do not consider roughly ${23/len(hetdex_SFGfiltered_cutouts)*100:.1f}\\\\%$ of sources $>60$ arcsec that could \n",
    "have been AGN remnant candidates.\"\"\")\n",
    "print(f\"\\n{1-test_size:.0%} of sources for training set:\\n\"\n",
    "     f\"{len(source_names_train)} sources, of which {np.sum(labels_train_full)} candidates\")\n",
    "\n",
    "print(f\"\\nAfter undersampling the majority class, we reduce the training set to:\\n\"\n",
    "     f\"{len(undersampled_train_ids)} sources, of which {np.sum(labels_train)} candidates\")\n",
    "\n",
    "print(f\"\\nSpecifically we undersampled the majority class from ${len(source_names_train)-np.sum(labels_train_full)}$ to $1,050$ sources,\"\n",
    "      f\" increasing the ratio AGN remnant candidate versus not-yet-inspected from 1 in 26 to\"\n",
    "      \" 1 in 10.\")\n",
    "\n",
    "print(f\"\\n{test_size:.0%} of sources for test set:\\n\"\n",
    "     f\"{len(source_names_test)} sources, of which {np.sum(labels_test)} candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All (undersampled) train data\n",
    "train_settings = deepcopy(hetdex_SFGfiltered_settingsfile)\n",
    "train_settings.store_filename = 'LoTSSDR2_hetdex_morethan60arcsec_noclip_sizeinvariant_SFGfiltered_train_undersampled'\n",
    "train_settings.run_id = 370\n",
    "train_settings.map_to_id = 370\n",
    "\n",
    "train_settings, train_cat, train_cat_path, \\\n",
    "    train_cutouts, train_cutouts_path, \\\n",
    "    train_bin_path = post.create_new_files_after_filtering(\n",
    "    undersampled_train_ids, hetdex_cutouts_train,\n",
    "    cat_train, train_settings,\n",
    "    data_directory,output_directory)\n",
    "\n",
    "# Just the train candidates\n",
    "cali_train_settings = deepcopy(hetdex_SFGfiltered_settingsfile)\n",
    "cali_train_settings.store_filename = 'LoTSSDR2_hetdex_morethan60arcsec_noclip_sizeinvariant_SFGfiltered_train_candidates'\n",
    "cali_train_settings.run_id = 371\n",
    "cali_train_settings.map_to_id = 370\n",
    "\n",
    "cali_train_settings, cali_train_cat, cali_train_cat_path, \\\n",
    "    cali_train_cutouts, cali_train_cutouts_path, \\\n",
    "    cali_train_bin_path = post.create_new_files_after_filtering(\n",
    "    undersampled_train_ids_cali, hetdex_cutouts_train,\n",
    "    cat_train, cali_train_settings,\n",
    "    data_directory,output_directory)\n",
    "\n",
    "# All test data\n",
    "test_settings = deepcopy(hetdex_SFGfiltered_settingsfile)\n",
    "test_settings.store_filename = 'LoTSSDR2_hetdex_morethan60arcsec_noclip_sizeinvariant_SFGfiltered_test'\n",
    "test_settings.run_id = 372\n",
    "test_settings.map_to_id = 370\n",
    "\n",
    "test_settings, test_cat, test_cat_path, \\\n",
    "    test_cutouts, test_cutouts_path, \\\n",
    "    test_bin_path = post.create_new_files_after_filtering(\n",
    "    idx_test, hetdex_SFGfiltered_cutouts,\n",
    "    hetdex_SFGfiltered_cat,test_settings,\n",
    "    data_directory,output_directory)\n",
    "\n",
    "# Just the test candidates\n",
    "cali_test_settings = deepcopy(hetdex_SFGfiltered_settingsfile)\n",
    "cali_test_settings.store_filename = 'LoTSSDR2_hetdex_morethan60arcsec_noclip_sizeinvariant_SFGfiltered_test_candidates'\n",
    "cali_test_settings.run_id = 373\n",
    "cali_test_settings.map_to_id = 370\n",
    "\n",
    "cali_test_settings, cali_test_cat, cali_test_cat_path, \\\n",
    "    cali_test_cutouts, cali_test_cutouts_path, \\\n",
    "    cali_test_bin_path = post.create_new_files_after_filtering(\n",
    "    idx_test_cali, hetdex_SFGfiltered_cutouts,\n",
    "    hetdex_SFGfiltered_cat,cali_test_settings,\n",
    "    data_directory,output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07781c46",
   "metadata": {},
   "source": [
    "# Cutout examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48396946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather examples\n",
    "np.random.seed(random_seed)\n",
    "candi_examples=[]\n",
    "noncandi_examples=[]\n",
    "n_examples=5\n",
    "for i, cutout in enumerate(train_cutouts):\n",
    "    if train_cat.iloc[i].Source_Name in cali_train_cat.Source_Name.values:\n",
    "        candi_examples.append(cutout)\n",
    "    else:\n",
    "        noncandi_examples.append(cutout)\n",
    "candi_examples = np.array(candi_examples)\n",
    "np.random.shuffle(candi_examples)\n",
    "noncandi_examples = np.array(noncandi_examples)\n",
    "np.random.shuffle(noncandi_examples)\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 10})\n",
    "f, axx = plt.subplots(n_examples,2,figsize=(4.5,10),\n",
    "                       constrained_layout = True)\n",
    "axx[0,1].set_title(\"Not yet inspected\")\n",
    "axx[0,0].set_title(\"AGN remnant candidates\")\n",
    "ll = np.shape(cutout)[0]\n",
    "w = int(ll/np.sqrt(2))\n",
    "ss=int((ll-w)/2)\n",
    "print(ll,w,ss)\n",
    "for i in range(n_examples):\n",
    "    im = np.array(deepcopy(noncandi_examples[i]))\n",
    "    im = im[ss:-ss,ss:-ss]\n",
    "    axx[i,1].imshow(im)\n",
    "for i in range(n_examples):\n",
    "    im = np.array(deepcopy(candi_examples[i]))\n",
    "    im = im[ss:-ss,ss:-ss]\n",
    "    axx[i,0].imshow(im)\n",
    "[axi.set_axis_off() for axi in axx.ravel()]\n",
    "plt.savefig(os.path.join(paper_fig_dir,f'cutout_examples.pdf'),bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a379ec8",
   "metadata": {},
   "source": [
    "# Train SOM with train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3fea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SOM\n",
    "s = deepcopy(train_settings)\n",
    "run_id = s.run_id\n",
    "print(\"Run Id of to train som is:\", run_id)\n",
    "print(\"Its name is:\", s.store_filename)\n",
    "\n",
    "s.data_dir = 'LoTSS_DR2/RA0h_field'\n",
    "with open(os.path.join(\n",
    "    data_directory,'run','trainSOM_SFGfiltered_undersampled.sh'),'w') as f:\n",
    "\n",
    "    # Define parameters\n",
    "    cutouts_bin_name = s.store_filename\n",
    "    #cutouts_binary_path\n",
    "    gpu_id = 0\n",
    "    som_size = 2\n",
    "    overwrite=s.overwrite\n",
    "    print(\"overwrite:\", overwrite)\n",
    "    som = s.som\n",
    "\n",
    "    # Create SOM info object\n",
    "    som.som_width = 9\n",
    "    som.som_height = 9\n",
    "    som.som_depth = 1\n",
    "    som.number_of_channels = 1\n",
    "    som.gauss_decrease = 0.9\n",
    "    som.gauss_end = 0.3\n",
    "    som.learning_constraint_decrease = 0.8\n",
    "    som.learning_constraint = som.som_width*som.som_height/100\n",
    "    som.gauss_start = max(som.som_width, som.som_height)/2\n",
    "    som.random_seed = 42\n",
    "    som.pbc = False\n",
    "    som.init = \"zero\"\n",
    "    som.layout = \"quadratic\"\n",
    "    som.training_dataset_name = s.store_filename\n",
    "    som.run_id = s.run_id\n",
    "    som.print()\n",
    "    som.output_directory = output_directory\n",
    "    som.save()\n",
    "    \n",
    "    rotated_size = int(round(rotated_size_arcsec/angular_resolution_LoTSS))\n",
    "    fullsize = int(np.ceil(rotated_size*np.sqrt(2)))\n",
    "    s.data_sir = 'LoTSS_DR2/RA0h_field'\n",
    "    print(\"Data dir\", s.data_dir)\n",
    "    # Get numpy list of cutouts and update catalogue to only contain sources that succesfully got extracted.\n",
    "    store_filename = s.store_filename\n",
    "\n",
    "    # Check cutouts shape\n",
    "    print(\"Cutouts shape (# cutouts, # channels, width, height) = \", \n",
    "          np.shape(hetdex_SFGfiltered_cutouts))\n",
    "    # Write cutouts to binary file (required file format for PINK software)\n",
    "    cutouts_binary_path = os.path.join(data_directory, s.store_filename + '.bin')\n",
    "    assert train_bin_path == cutouts_binary_path\n",
    "    post.write_numpy_to_binary_v2(train_bin_path, train_cutouts,\n",
    "                                    som.layout, overwrite=True)\n",
    "    # Write train bash scripts\n",
    "    s.som = som\n",
    "    s.save(output_directory)\n",
    "    s.flip_axis1=False\n",
    "    s.flip_axis2=False\n",
    "    s.rot90=False\n",
    "    # Write train bash script\n",
    "    s.som = som\n",
    "    bash_path = os.path.join(run_dir,f'{s.store_filename}_ID{run_id}.sh')\n",
    "    bashstring = post.write_bash_script_to_run_pink_v2(som, run_id, s.store_filename,\n",
    "                                                            gpu_id,\n",
    "                                                            data_directory.replace(\n",
    "                                                                'data2','data'),\n",
    "        output_directory.replace('data2','data'), bash_path, verbose=False)\n",
    "    print(bashstring,file=f)\n",
    "    print(\"Bash script to train SOM:\", bash_path)\n",
    "    \n",
    "    force_chosen_som_index=25\n",
    "    print(s.run_id)\n",
    "    som_v2, data_map_v2, data_som_v2, trained_path_v2, \\\n",
    "        distance_to_bmu_sorted_down_id_v2, \\\n",
    "        closest_prototype_id_v2, cat_v2, _ = post.inspect_trained_som(s.run_id, \n",
    "                data_directory, output_directory, figures_dir, fit_threshold=0.077,\n",
    "             verbose=False, align_prototypes=True, normalize=False,compress=True,\n",
    "             flip_axis0=False,flip_axis1=False,rot90=False,\n",
    "                version=2, zoom_in=True, save=False, \n",
    "                catalogue_name=train_cat,\n",
    "                overwrite=True, force_chosen_som_index=force_chosen_som_index)\n",
    "    print(\"\\nRun bash script to train SOM:\", bash_path)\n",
    "    cali_SFGfiltered_settingsfile.map_to_binpath = trained_path_v2\n",
    "    print('\\n\\nSOM',som_v2.print(),'\\n\\n')\n",
    "    \n",
    "    # Map train remnants to trained SOM\n",
    "    map_path = os.path.join(map_dir,f'{cali_train_settings.store_filename}_ID{cali_train_settings.run_id}_mapped_to_ID{s.run_id}.bin')\n",
    "    new_bin_path =  os.path.join(data_directory,cali_train_settings.store_filename +'.bin')\n",
    "    mapstring = post.map_dataset_to_trained_som(som, \n",
    "                new_bin_path, \n",
    "                map_path, trained_path_v2,\n",
    "        gpu_id, use_gpu=True, verbose=True, version=2,\n",
    "        alternate_neuron_dimension=None, use_cuda_visible_devices=True,\n",
    "        rotation_path=None, circular_shape=False)\n",
    "    cali_train_settings.map_path = map_path\n",
    "    cali_train_settings.save(output_directory)\n",
    "    \n",
    "    # Map test set to trained SOM\n",
    "    map_path = os.path.join(map_dir,f'{test_settings.store_filename}_ID{test_settings.run_id}_mapped_to_ID{s.run_id}.bin')\n",
    "    new_bin_path =  os.path.join(data_directory,\n",
    "                        test_settings.store_filename +'.bin')\n",
    "    mapstring = post.map_dataset_to_trained_som(som, \n",
    "                new_bin_path, \n",
    "                map_path, trained_path_v2,\n",
    "        gpu_id, use_gpu=True, verbose=True, version=2,\n",
    "        alternate_neuron_dimension=None, use_cuda_visible_devices=True,\n",
    "        rotation_path=None, circular_shape=False)\n",
    "    test_settings.map_path = map_path\n",
    "    test_settings.save(output_directory)\n",
    "    \n",
    "    map_path = os.path.join(map_dir,f'{train_settings.store_filename}_ID{train_settings.run_id}_mapped_to_ID{s.run_id}.bin')\n",
    "    new_bin_path =  os.path.join(data_directory,train_settings.store_filename +'.bin')\n",
    "    train_settings.som = som_v2\n",
    "    train_settings.map_path = som_v2.map_path\n",
    "    train_settings.save(output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a5166",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "captions2=[f'All training sources\\nmapped to trained SOM']\n",
    "captions3=[f'{len(cali_train_cutouts)} sources labelled as\\nAGN remnant candidate\\nduring initial visual inspection\\nmapped to trained SOM']\n",
    "\n",
    "cali_train_settings.zoom_in = True\n",
    "data_map_train, data_map_train_remnant, counts1, counts2 = post.plot_som_and_two_heatmaps(\n",
    "    train_settings, cali_train_settings,\n",
    "   output_directory,map_dir, save=True,compress=False,\n",
    "    save_path=os.path.join(paper_fig_dir,f'trained_som_id{train_settings.run_id}_and_heatmaps.pdf'),\n",
    "    specific_som=train_settings,\n",
    "    highlight=[],highlight_colors=[],\n",
    "    annotations_for_paper=False,\n",
    "    save_dir=figures_dir,\n",
    "    caption2=captions2[0], caption3=captions3[0],\n",
    "    caption1=f'9x9 SOM\\ntrained with {len(train_cutouts)} radio sources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea52ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "captions2=['Sources >60\\\" \\nin HETDEX\\nnearby SFGs filtered\\nmapped to trained SOM']\n",
    "captions3=[f'{len(cali_train_cutouts)} AGN remnant candidates\\naccepted by visual inspection\\nmapped to trained SOM']\n",
    "\n",
    "captions2=[f'All training sources\\nmapped to trained SOM']\n",
    "captions3=[f'{len(cali_train_cutouts)} sources labelled as\\nAGN remnant candidate\\nduring initial visual inspection\\nmapped to trained compressed SOM']\n",
    "\n",
    "cali_train_settings.zoom_in = True\n",
    "data_map_train_compressed, data_map_train_remnant_compressed, counts1, counts2 = post.plot_som_and_two_heatmaps(\n",
    "    train_settings, cali_train_settings,\n",
    "   output_directory,map_dir, save=True,compress=True,\n",
    "        save_path=os.path.join(paper_fig_dir,f'trained_som_id{train_settings.run_id}_compressed_and_heatmaps.pdf'),\n",
    "\n",
    "    specific_som=train_settings,\n",
    "    highlight=[],highlight_colors=[],\n",
    "    annotations_for_paper=False,\n",
    "    save_dir=figures_dir,\n",
    "    caption2=captions2[0], caption3=captions3[0],\n",
    "    caption1=f'5x5 compressed SOM\\ntrained with {len(train_cutouts)} radio sources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa1c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the test set\n",
    "# The two heatmaps should be similar\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "captions2=['Sources >60\\\" \\nin HETDEX\\nnearby SFGs filtered\\nmapped to trained SOM']\n",
    "captions3=[f'{len(test_cutouts)} sources from our test set\\nmapped to trained SOM']\n",
    "\n",
    "_, data_map_test_compressed, counts1, counts2 = post.plot_som_and_two_heatmaps(\n",
    "    train_settings, test_settings,\n",
    "   output_directory,map_dir, save=False,compress=True,\n",
    "    #specific_som=train_settings,\n",
    "    highlight=[],highlight_colors=[],\n",
    "    annotations_for_paper=False,\n",
    "    save_dir=figures_dir,\n",
    "    caption2=captions2[0], caption3=captions3[0],\n",
    "    caption1=f'5x5 compressed SOM\\ntrained with {len(train_cutouts)} radio sources')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852241ab",
   "metadata": {},
   "source": [
    "# Exploring alternative morphological metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27d18a",
   "metadata": {},
   "source": [
    "## Sort using Concentration index (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c2de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelvalues_within_radius(image, radius, debug=False):\n",
    "    \"\"\"Given an image, determine the summed pixelvalue within a circle\n",
    "    of radius r.\"\"\"\n",
    "    assert len(np.shape(image)) == 2\n",
    "    width, height = np.shape(image)\n",
    "    assert radius <= width and radius <= height\n",
    "    image_copy = deepcopy(image)\n",
    "    initial_sum = np.sum(image_copy)\n",
    "    a, b = int(height/2), int(width/2)\n",
    "\n",
    "    y,x = np.ogrid[-a:int(height)-a, -b:int(width)-b]\n",
    "    mask = x*x + y*y > radius*radius\n",
    "    \n",
    "    if debug:\n",
    "        # debug plot\n",
    "        image_copy[mask] = 2\n",
    "        plt.figure()\n",
    "        plt.imshow(image_copy, origin='lower', cmap='viridis')\n",
    "        plt.grid(False)\n",
    "        plt.show()\n",
    "        \n",
    "    image_copy[mask] = 0\n",
    "    return np.sum(image_copy)/initial_sum\n",
    "    \n",
    "    \n",
    "def concentration_index(image, r_inner_fraction=0.2, r_outer_fraction=0.8):\n",
    "    \"\"\"Given an image, determine the Concentration index as \n",
    "    defined in Conselice 2014 review on galaxy morphology.\"\"\"\n",
    "    \n",
    "    width, height = np.shape(image)\n",
    "    assert width == height\n",
    "\n",
    "    radii = np.linspace(0,width/2,100)\n",
    "    r_inner, r_outer= 0, 0\n",
    "    inner_reached, outer_reached = False, False\n",
    "    fluxfractions = [pixelvalues_within_radius(image, r) for r in radii]\n",
    "    \n",
    "    for r,v in zip(radii,fluxfractions): \n",
    "        if not inner_reached and v > r_inner_fraction:\n",
    "            r_inner = r\n",
    "            inner_reached = True        \n",
    "        if not outer_reached and v > r_outer_fraction:\n",
    "            r_outer = r\n",
    "            outer_reached = True\n",
    "    return 5*np.log(r_outer/r_inner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34a652",
   "metadata": {},
   "source": [
    "## Sort using Gini coefficient (G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9319e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(image):\n",
    "    \"\"\"Given an image, determine the Gini coefficient as \n",
    "    defined in Lisker 2008.\"\"\"\n",
    "    assert len(np.shape(image)) == 2\n",
    "    width, height = np.shape(image)\n",
    "    image_copy = deepcopy(image)\n",
    "    radii = np.linspace(0,width/2,100)\n",
    "    new_radius=0\n",
    "    \n",
    "    # Determine 95% flux containing radius\n",
    "    for radius in radii:\n",
    "        f = pixelvalues_within_radius(image, radius, debug=False)\n",
    "        if f > 0.95:\n",
    "            new_radius = radius\n",
    "            break\n",
    "    #print(\"Old radius:\", width/2,\"New radius is:\", new_radius)\n",
    "    a, b = int(height/2), int(width/2)\n",
    "    y,x = np.ogrid[-a:int(height)-a, -b:int(width)-b]\n",
    "    mask = x*x + y*y > new_radius**2\n",
    "    image_copy[mask] = np.nan\n",
    "    raveled = np.ravel(image_copy)\n",
    "    raveled = raveled[~np.isnan(raveled)]\n",
    "    n = len(raveled)\n",
    "\n",
    "    f_average = np.abs(np.mean(raveled))\n",
    "    sorted_pixels = np.sort(np.abs(raveled))\n",
    "\n",
    "    #print(\"summed second term\",np.sum([(2*i -n - 1)*v for i, v in enumerate(sorted_pixels)]))\n",
    "    return np.sum([(2*i -n - 1)*v for i, v in enumerate(sorted_pixels)])/(f_average*n*(n-1))\n",
    "def flux_radius(image, flux_fraction_contained= 0.95):\n",
    "    \"\"\"Given an image, determine the Gini coefficient as \n",
    "    defined in Lisker 2008.\"\"\"\n",
    "    assert len(np.shape(image)) == 2\n",
    "    width, height = np.shape(image)\n",
    "    image_copy = deepcopy(image)\n",
    "    radii = np.linspace(0,width/2,100)\n",
    "    new_radius=0\n",
    "    \n",
    "    # Determine 95% flux containing radius\n",
    "    for radius in radii:\n",
    "        f = pixelvalues_within_radius(image, radius, debug=False)\n",
    "        if f > flux_fraction_contained:\n",
    "            new_radius = radius\n",
    "            break\n",
    "    return new_radius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9692d1",
   "metadata": {},
   "source": [
    "## Sort using Clumpiness index (S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdd4a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "def clumpiness_index(image, smoothing_kernel=4, debug=False):\n",
    "    \"\"\"Given an image, determine the Clumpiness index as \n",
    "    defined in Conselice 2014 review on galaxy morphology.\"\"\"\n",
    "    width, height = np.shape(image)\n",
    "    assert width == height\n",
    "    assert len(np.shape(image)) == 2\n",
    "    image_copy = deepcopy(image)\n",
    "    initial_sum = np.sum(image_copy)\n",
    "    smoothed_image = gaussian_filter(image, smoothing_kernel)\n",
    "    if debug:\n",
    "        # Show concerning image\n",
    "        print(\"Clumpiness:\",10*(np.sum(np.abs(image_copy-smoothed_image))/initial_sum))\n",
    "        image_copy[0,0] = 1\n",
    "        smoothed_image[0,0] = 1\n",
    "        plt.imshow(image_copy, origin='lower', cmap='viridis')\n",
    "        plt.colorbar()\n",
    "        plt.grid(False)\n",
    "        plt.show()\n",
    "        plt.imshow(smoothed_image, origin='lower', cmap='viridis')\n",
    "        plt.grid(False)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    return 10*(np.sum(np.abs(image_copy-smoothed_image))/initial_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce6bc8",
   "metadata": {},
   "source": [
    "# plot Morphological metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22aa762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics for calibration set\n",
    "cali_concentrations = np.array([concentration_index(image, r_inner_fraction=0.2, \n",
    "        r_outer_fraction=0.8) for image in cali_train_cutouts])\n",
    "cali_clumpinesses = np.array([clumpiness_index(image, smoothing_kernel=8) \n",
    "        for image in cali_train_cutouts])\n",
    "cali_ginis = np.array([gini_index(image) \n",
    "                       for image in cali_train_cutouts])\n",
    "cali_euclid = np.min(data_map_train_remnant_compressed,axis=1)\n",
    "\n",
    "# For hetdex filtered etc\n",
    "hetdex_concentrations = np.array([concentration_index(image, r_inner_fraction=0.2, \n",
    "        r_outer_fraction=0.8) for image in train_cutouts])\n",
    "hetdex_clumpinesses = np.array([clumpiness_index(image, smoothing_kernel=8) \n",
    "        for image in train_cutouts])\n",
    "hetdex_ginis = np.array([gini_index(image) \n",
    "                      for image in train_cutouts])\n",
    "hetdex_euclid = np.min(data_map_train_compressed,axis=1)\n",
    "#hetdex_SFGfiltered_data_map_compressed, data_map_remnant_compressed, data_map_nonremnant_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374aafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Euclidean norm vs concentration index\n",
    "rows,cols = 4,4\n",
    "ms=4\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "\n",
    "f, ax = plt.subplots(cols,rows,figsize=(10,10))\n",
    "spacing=0\n",
    "plt.subplots_adjust(wspace=spacing,hspace=spacing)\n",
    "dc = {'Concentration index':cali_concentrations,'Gini coefficient':cali_ginis,\n",
    "     'Clumpiness index':cali_clumpinesses,'Euclidean norm':cali_euclid}\n",
    "da = {'Concentration index':hetdex_concentrations,'Gini coefficient':hetdex_ginis,\n",
    "     'Clumpiness index':hetdex_clumpinesses,'Euclidean norm':hetdex_euclid}\n",
    "    \n",
    "for row_idx, ys in enumerate(['Euclidean norm','Concentration index','Gini coefficient','Clumpiness index']):\n",
    "    #for col_idx, ys in enumerate(['Euclidean norm','Concentration index','Gini index','Clumpiness index']):\n",
    "    for col_idx, xs in enumerate(['Euclidean norm','Concentration index','Gini coefficient','Clumpiness index']):\n",
    "        if rows-row_idx +col_idx > 3:\n",
    "            ax[row_idx,col_idx].axis('off')\n",
    "            continue\n",
    "        if rows -1 != row_idx:\n",
    "            ax[row_idx,col_idx].xaxis.set_major_locator(plt.NullLocator())\n",
    "        else:\n",
    "            ax[row_idx,col_idx].set_xlabel(xs.replace(' ','\\n'))\n",
    "        if 0 != col_idx:\n",
    "            ax[row_idx,col_idx].yaxis.set_major_locator(plt.NullLocator())\n",
    "        else:\n",
    "            ax[row_idx,col_idx].set_ylabel(ys.replace(' ','\\n'))\n",
    "        l1 = ax[row_idx,col_idx].scatter(da[xs],da[ys],\n",
    "                    s=ms,label='Rejected candidates')\n",
    "        l2 = ax[row_idx,col_idx].scatter(dc[xs],dc[ys],\n",
    "                    s=ms, label='Accepted candidates')\n",
    "    \n",
    "    \n",
    "plt.savefig(os.path.join(paper_fig_dir,\"metrics_cali_hetdex.pdf\"),bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Min and max value comparisons\")\n",
    "print(f\"cali concentration ranges from {np.min(cali_concentrations):.1f} to {np.max(cali_concentrations):.1f}\")\n",
    "print(f\"all concentration ranges from {np.min(hetdex_concentrations):.1f} to {np.max(hetdex_concentrations):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4fb53c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot all source above clumpiness index of 4\n",
    "from matplotlib.patches import Ellipse\n",
    "np.random.seed(random_seed)\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "def plot_optical_metric_examples(title, condition, savetitle='', save=True,flux_radii=None):\n",
    "    w,h=3,3\n",
    "    fig, ax = plt.subplots(w,h, figsize=(10,10.5),constrained_layout = True)\n",
    "    spacing=0.0\n",
    "    axr = ax.ravel()\n",
    "    plt.suptitle(title)\n",
    "    cuts = deepcopy(train_cutouts[condition])\n",
    "    shuf = list(range(len(cuts)))\n",
    "    np.random.shuffle(shuf)\n",
    "    if not flux_radii is None:\n",
    "        flux_r = deepcopy(flux_radii[condition])\n",
    "        flux_r = flux_r[shuf]\n",
    "    for i_c, c in enumerate(cuts[shuf][:w*h]):\n",
    "        axr[i_c].imshow(c)\n",
    "        if not flux_radii is None:\n",
    "            ww,hh= c.shape\n",
    "            axr[i_c].add_patch(Ellipse(xy=(ww/2,hh/2),width=2*flux_r[i_c],height=2*flux_r[i_c], \n",
    "                        edgecolor='r', fc='None', lw=2))\n",
    "            axr[i_c].text(ww/2,hh/2,f\"{2*flux_r[i_c]:.1f}\")\n",
    "        axr[i_c].axis('off')\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(paper_fig_dir,savetitle+'.pdf'))\n",
    "    plt.show()\n",
    "low, high = np.percentile(hetdex_ginis,[20,80])\n",
    "plot_optical_metric_examples(f'Gini coefficient < {low:.2f}', hetdex_ginis < low, \n",
    "                             savetitle='Gini_coefficient_low')\n",
    "plot_optical_metric_examples(f'Gini coefficient > {high:.2f}', hetdex_ginis > high,\n",
    "                             savetitle='Gini_coefficient_high')\n",
    "low, high = np.percentile(hetdex_concentrations,[20,80])\n",
    "plot_optical_metric_examples(f'Concentration index < {low:.2f}', hetdex_concentrations < low, \n",
    "                             savetitle='Concentration_index_low')\n",
    "plot_optical_metric_examples(f'Concentration index > {high:.2f}', hetdex_concentrations > high,\n",
    "                             savetitle='Concentration_index_high')\n",
    "low, high = np.percentile(hetdex_clumpinesses,[20,80])\n",
    "plot_optical_metric_examples(f'Clumpiness index < {low:.2f}', hetdex_clumpinesses < low, \n",
    "                             savetitle='Clumpiness_index_low')\n",
    "plot_optical_metric_examples(f'Clumpiness index > {high:.2f}', hetdex_clumpinesses > high,\n",
    "                             savetitle='Clumpiness_index_high')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d8008",
   "metadata": {},
   "source": [
    "# Decision Tree time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7723928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start from SFG filtered cat >60arcsec\n",
    "\n",
    "# Compile source features and source labels (agn remnant candidate or not)\n",
    "# Features to collect:\n",
    "# 1. Number of AGN remnant candidates in the best matching neuron of the source\n",
    "# 2. Total flux / peak flux\n",
    "# 3. Total flux\n",
    "# 4. Major axis / minor axis\n",
    "# 5. Euclidean norm\n",
    "# 6. Concentration index\n",
    "# 7. Gini coefficient\n",
    "# 8. Clumpiness index\n",
    "# 9. Angular separation to the nearest cluster? (as a higher magnetic background field should allow us to observe AGN remnants for a longer time?)\n",
    "# Or even better: Distance to the nearest cluster in Mpc\n",
    "# Finally Labels\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# 1. best matching neuron\n",
    "bmn = np.argmin(data_map_train_compressed,axis=1)\n",
    "l = len(bmn)\n",
    "# 2.\n",
    "total_to_peak_fluxes = train_cat.Total_flux.values/train_cat.Peak_flux.values\n",
    "assert l == len(total_to_peak_fluxes)\n",
    "# 3.\n",
    "major_to_minor_axes = train_cat.source_size.values/train_cat.source_width.values\n",
    "assert l == len(major_to_minor_axes)\n",
    "# 4.\n",
    "euclidean_norms = np.min(data_map_train_compressed,axis=1)\n",
    "assert l == len(euclidean_norms)\n",
    "# 5. \n",
    "all_concentrations = np.array([concentration_index(image, r_inner_fraction=0.2, \n",
    "        r_outer_fraction=0.8) for image in train_cutouts])\n",
    "assert l == len(all_concentrations)\n",
    "# 6.\n",
    "all_ginis = np.array([gini_index(image) for image in train_cutouts])\n",
    "assert l == len(all_ginis)\n",
    "# 7.\n",
    "all_clumpinesses = np.array([clumpiness_index(image, smoothing_kernel=8) \n",
    "        for image in train_cutouts])\n",
    "assert l == len(all_clumpinesses)\n",
    "# 8. Haralick features\n",
    "haralicks = []\n",
    "for cutout in train_cutouts:\n",
    "    #calculate haralick features\n",
    "    data = deepcopy(cutout)*256\n",
    "    # Reduce the cutout intensity levels to 256 integer values\n",
    "    data = data.astype(np.uint8)\n",
    "    # Further reduce the cutout intensity levels to 32 integer values\n",
    "    # as advocated by M.A. Tahir, A. Bouridane, F. Kurugollu, A. Amira\n",
    "    # Accelerating computation of GLCM and Haralick texture features on reconfigurable hardware\n",
    "    #data = np.array([list(map(int,aa/8)) for aa in data])\n",
    "    haralick_features = mh.features.haralick(data, return_mean=True)\n",
    "    haralicks.append(haralick_features)\n",
    "haralicks = np.array(haralicks)\n",
    "#set up the HDBSCAN clusterer - see params for more details, but this seems to do okay\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=32,min_samples=32,\n",
    "                            algorithm='best', prediction_data=True,\n",
    "                            cluster_selection_method='eom',\n",
    "                            metric='euclidean')\n",
    "\n",
    "clusterer = clusterer.fit(haralicks)\n",
    "\n",
    "#get a list of unique labels and the number of counts of each label\n",
    "#label = -1 is 'noise' - i.e. couldn't be fit to a cluster\n",
    "clustered_haralicks = clusterer.labels_\n",
    "ulab,ucount= np.unique(clustered_haralicks,return_counts=True)\n",
    "print(f\"Hdbscan generated {len(ulab)} clusters: {ulab} Containing {ucount} sources each.\")\n",
    "assert l == len(clustered_haralicks)\n",
    "\n",
    "# Labels\n",
    "labels_train = np.array([sn in cali_train_cat.Source_Name.values\n",
    " for sn in train_cat.Source_Name.values])\n",
    "\n",
    "# Combine features and make random train test split\n",
    "combined_data = pd.DataFrame({\n",
    "                            'Source Name':train_cat.Source_Name.values,\n",
    "                             'Remnants per SOM neuron':bmn,\n",
    "                            # bmn will be turned into a ratio within\n",
    "                            # each cross-fold\n",
    "                            'Remnants ratio per SOM neuron':bmn,\n",
    "                             'Total/peak flux':total_to_peak_fluxes,\n",
    "                             'Major/minor axis':major_to_minor_axes,\n",
    "                             'Euclidean norm':euclidean_norms,\n",
    "                             'Concentration index':all_concentrations,\n",
    "                             'Gini coefficient':all_ginis,\n",
    "                             'Clumpiness index':all_clumpinesses,\n",
    "                            # clustered_haralicks will be turned into a ratio within\n",
    "                            # each cross-fold\n",
    "                             'Clustered Haralick ratio':clustered_haralicks,\n",
    "})\n",
    "features_train=combined_data.to_numpy()\n",
    "feature_list=combined_data.keys()[1:]\n",
    "print(\"len dataframe:\", len(combined_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f5c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the test set\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# 1. best matching neuron\n",
    "bmn = np.argmin(data_map_test_compressed,axis=1)\n",
    "l = len(bmn)\n",
    "# 2.\n",
    "total_to_peak_fluxes = test_cat.Total_flux.values/test_cat.Peak_flux.values\n",
    "assert l == len(total_to_peak_fluxes)\n",
    "# 3.\n",
    "major_to_minor_axes = test_cat.source_size.values/test_cat.source_width.values\n",
    "assert l == len(major_to_minor_axes)\n",
    "# 4.\n",
    "euclidean_norms = np.min(data_map_test_compressed,axis=1)\n",
    "assert l == len(euclidean_norms)\n",
    "# 5. \n",
    "all_concentrations = np.array([concentration_index(image, r_inner_fraction=0.2, \n",
    "        r_outer_fraction=0.8) for image in test_cutouts])\n",
    "assert l == len(all_concentrations)\n",
    "# 6.\n",
    "all_ginis = np.array([gini_index(image) for image in test_cutouts])\n",
    "assert l == len(all_ginis)\n",
    "# 7.\n",
    "all_clumpinesses = np.array([clumpiness_index(image, smoothing_kernel=8) \n",
    "        for image in test_cutouts])\n",
    "assert l == len(all_clumpinesses)\n",
    "# 8. Haralicks\n",
    "haralicks = []\n",
    "for cutout in test_cutouts:\n",
    "    #calculate haralick features\n",
    "    data = deepcopy(cutout)*256\n",
    "    # Reduce the cutout intensity levels to 256 integer values\n",
    "    data = data.astype(np.uint8)\n",
    "    # Further reduce the cutout intensity levels to 32 integer values\n",
    "    # as advocated by M.A. Tahir, A. Bouridane, F. Kurugollu, A. Amira\n",
    "    # Accelerating computation of GLCM and Haralick texture features on reconfigurable hardware\n",
    "    #data = np.array([list(map(int,aa/8)) for aa in data])\n",
    "    haralick_features = mh.features.haralick(data, return_mean=True)\n",
    "    haralicks.append(haralick_features)\n",
    "haralicks = np.array(haralicks)\n",
    "# Use previously trained clusterer\n",
    "# https://hdbscan.readthedocs.io/en/latest/prediction_tutorial.html\n",
    "test_labels, strengths = hdbscan.approximate_predict(clusterer, haralicks)\n",
    "\n",
    "#get a list of unique labels and the number of counts of each label\n",
    "#label = -1 is 'noise' - i.e. couldn't be fit to a cluster\n",
    "ulab,ucount= np.unique(test_labels,return_counts=True)\n",
    "print(f\"Hdbscan generated {len(ulab)} clusters: {ulab} Containing {ucount} sources each.\")\n",
    "assert l == len(test_labels)\n",
    "\n",
    "# Labels\n",
    "labels_test = np.array([sn in cali_test_cat.Source_Name.values\n",
    " for sn in test_cat.Source_Name.values])\n",
    "\n",
    "# Combine features and make random train test split\n",
    "combined_data = pd.DataFrame({\n",
    "                            'Source Name':test_cat.Source_Name.values,\n",
    "                             'Remnants per SOM neuron':bmn,\n",
    "                            # bmn will be turned into a ratio within\n",
    "                            # each cross-fold\n",
    "                            'Remnants ratio per SOM neuron':bmn, #np.array([0 for _ in range(l)]),\n",
    "                             'Total/peak flux':total_to_peak_fluxes,\n",
    "                             'Major/minor axis':major_to_minor_axes,\n",
    "                             'Euclidean norm':euclidean_norms,\n",
    "                             'Concentration index':all_concentrations,\n",
    "                             'Gini coefficient':all_ginis,\n",
    "                             'Clumpiness index':all_clumpinesses,\n",
    "                            # clustered_haralicks will be turned into a ratio within\n",
    "                            # each cross-fold\n",
    "                             'Clustered Haralick ratio':test_labels,\n",
    "})\n",
    "features_test=combined_data.to_numpy()\n",
    "print(\"len dataframe:\", len(combined_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if HDBScan approximate predict equals clusterer.fit when fed the same cutouts\n",
    "first_ten = clustered_haralicks[:10]\n",
    "# Haralicks\n",
    "haralicks = []\n",
    "for cutout in train_cutouts[:10]:\n",
    "    data = deepcopy(cutout)*256\n",
    "    data = data.astype(np.uint8)\n",
    "    haralick_features = mh.features.haralick(data, return_mean=True)\n",
    "    haralicks.append(haralick_features)\n",
    "haralicks = np.array(haralicks)\n",
    "debug_labels, strengths = hdbscan.approximate_predict(clusterer, haralicks)\n",
    "assert all(first_ten == debug_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b680d665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print examples of sources in each cluster\n",
    "#for cutout, label in zip(train_cutouts,clustered_haralicks):\n",
    "    \n",
    "np.random.seed(random_seed)\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "def plot_haralick_examples(title, condition, savetitle='', save=True):\n",
    "    w,h=3,3\n",
    "    fig, ax = plt.subplots(w,h, figsize=(10,10.5),constrained_layout = True)\n",
    "    spacing=0.0\n",
    "    axr = ax.ravel()\n",
    "    plt.suptitle(title)\n",
    "    cuts = deepcopy(train_cutouts[condition])\n",
    "    shuf = list(range(len(cuts)))\n",
    "    np.random.shuffle(shuf)\n",
    "    for i_c, c in enumerate(cuts[shuf][:w*h]):\n",
    "        axr[i_c].imshow(c)\n",
    "        axr[i_c].axis('off')\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(paper_fig_dir,savetitle+'.pdf'))\n",
    "    plt.show()\n",
    "save=False\n",
    "plot_haralick_examples(f'Haralick cluster -1 (\\'noise\\' cluster)', clustered_haralicks == -1, \n",
    "                             save=save,savetitle='haralick_minus1')\n",
    "plot_haralick_examples(f'Haralick cluster 0', clustered_haralicks == 0, \n",
    "                             save=save,savetitle='haralick_0')\n",
    "plot_haralick_examples(f'Haralick cluster 1', clustered_haralicks == 1, \n",
    "                             save=save,savetitle='haralick_1')\n",
    "plot_haralick_examples(f'Haralick cluster 2', clustered_haralicks == 2, \n",
    "                             save=save,savetitle='haralick_2')\n",
    "plot_haralick_examples(f'Haralick cluster 3', clustered_haralicks == 3, \n",
    "                             save=save,savetitle='haralick_3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcenames_train = np.array([f[0] for f in features_train])\n",
    "sourcenames_test = np.array([f[0] for f in features_test])\n",
    "features_train = np.array([f[1:] for f in features_train])\n",
    "features_test = np.array([f[1:] for f in features_test])\n",
    "\n",
    "\n",
    "print(pd.DataFrame({\"labels_train\":labels_train}).labels_train.value_counts(\n",
    "    normalize = True))\n",
    "print(pd.DataFrame({\"labels_test\":labels_test}).labels_test.value_counts(\n",
    "    normalize = True))\n",
    "print(f\"Train: {np.sum(labels_train)} remnants, {len(labels_train)-np.sum(labels_train)} non-remnants\")\n",
    "print(f\"Test: {np.sum(labels_test)} remnants, {len(labels_test)-np.sum(labels_test)} non-remnants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0546894a",
   "metadata": {},
   "source": [
    "## Employ gridsearch to find good RF parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0103f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_train), len(labels_train), features_train.shape, labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ab576",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "f_scorer = make_scorer(fbeta_score, beta=2)\n",
    "scoring = f_scorer\n",
    "redo=False\n",
    "if redo:\n",
    "    # Set up RF\n",
    "    rf = RandomForestClassifier(n_estimators=5000, random_state=random_seed,\n",
    "                        max_depth = 2, max_features=0.2, \n",
    "                        class_weight='balanced')\n",
    "\n",
    "    # Set up stratified split\n",
    "    cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=random_seed)\n",
    "    # Set up parameters to do gridsearch over\n",
    "    param_grid = [{'max_depth': [2,4,8,16,32], \n",
    "                   'max_features': [0.2,0.3,0.4,0.5],\n",
    "                   'class_weight': [{0: x, 1: 1.0-x} for x in [0.01,0.04,0.16,0.32,0.5]]\n",
    "                  } ]\n",
    "    # Gridsearch with full (unbalanced) train dataset\n",
    "    start = time.time()\n",
    "    clf = GridSearchCV(rf, param_grid, scoring=scoring, n_jobs=-1, refit=True, cv=cv, verbose=0, \n",
    "                  return_train_score=False)\n",
    "    clf.fit(features_train, labels_train)\n",
    "    print(f\"Cross-validation custom gridsearch took ${(time.time()-start)/60:.2f}$ min.\")\n",
    "    unbalanced_par_score = (clf.best_params_, clf.best_score_)\n",
    "    print(\"Best parameters:\",unbalanced_par_score)\n",
    "else:\n",
    "    # Set up RF with previously found best values\n",
    "    cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=random_seed)\n",
    "    clf = RandomForestClassifier(n_estimators=5000, random_state=random_seed,\n",
    "                        max_depth = 8, max_features=0.3, \n",
    "                        class_weight={0: 0.04, 1: 0.96})\n",
    "    clf.best_params_ = {'class_weight': {0: 0.04, 1: 0.96}, 'max_depth': 8, 'max_features': 0.3}\n",
    "    unbalanced_par_score = ({'class_weight': {0: 0.04, 1: 0.96}, 'max_depth': 8, 'max_features': 0.3}, 0.6754247726575159)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71177f",
   "metadata": {},
   "source": [
    "## Get feature importance and test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8b2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "# Fill features\n",
    "features_train2, remnant_dict, all_dict, remnant_dict_hard, all_dict_hard, \\\n",
    "                 = insert_local_remnant_ratios(\n",
    "                features_train, labels_train, debug=False)\n",
    "features_test2 = insert_local_test_ratios(features_test, remnant_dict, all_dict, \\\n",
    "                                    remnant_dict_hard, all_dict_hard)\n",
    "# Final training on full unbalanced training set\n",
    "best_rf = RandomForestClassifier(n_estimators=1000, random_state=random_seed,\n",
    "                    max_depth = unbalanced_par_score[0]['max_depth'], \n",
    "                    max_features=unbalanced_par_score[0]['max_features'], \n",
    "                    class_weight=unbalanced_par_score[0]['class_weight'])\n",
    "best_rf.fit(features_train2, labels_train)\n",
    "print(f\"\"\"In the cross-validation phase of training our RF, \n",
    "the grid-search reveals that a maximum tree depth of ${clf.best_params_['max_depth']}$,\n",
    "a maximum feature-ratio of ${clf.best_params_['max_features']}$ \n",
    "and a class weight of ${clf.best_params_['class_weight'][0]}$ for our majority class \n",
    "(and ${clf.best_params_['class_weight'][1]}$ for our minority class),\n",
    "are good parameter choices for our RF when optimizing for recall. \n",
    "Refitting our RF using these parameters on the full training set yields the following performance score on the test set.\"\"\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(best_rf.feature_importances_)# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) \n",
    "                       for feature, importance in zip(feature_list, importances)]# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, \n",
    "                             key = lambda x: x[1], reverse = True)# Print out the feature and importances \n",
    "[print('{:20} & ${}$ \\\\\\\\'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "# Predict on testset\n",
    "predictions_rf = best_rf.predict(features_test2)\n",
    "print(classification_report(labels_test, predictions_rf))\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(labels_test, predictions_rf, labels=best_rf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=best_rf.classes_)\n",
    "disp.plot()\n",
    "plt.title('For full testset')\n",
    "plt.ylabel('AGN remnant candidate')\n",
    "plt.xlabel('AGN remnant candidate predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f32a82",
   "metadata": {},
   "source": [
    "## Find best threshold for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca7bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "thres=0.25 #f2 5000trees\n",
    "\n",
    "pred = np.array([True if b>thres else False \n",
    "                    for a,b in best_rf.predict_proba(features_train2)])\n",
    "cm_train = confusion_matrix(labels_train,pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=best_rf.classes_)\n",
    "disp.plot(cmap='gray')\n",
    "plt.title('Train set')\n",
    "plt.ylabel('AGN remnant candidate')\n",
    "plt.xlabel('AGN remnant candidate predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a044015",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "print(\"recall\",unbalanced_par_score)\n",
    "thres=0.25#f2 5000trees\n",
    "\n",
    "pred = np.array([True if b>thres else False \n",
    "                    for a,b in best_rf.predict_proba(features_test2)])\n",
    "cm = confusion_matrix(labels_test,pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_rf.classes_)\n",
    "disp.plot(cmap='gray')\n",
    "# plt.title('For full testset')\n",
    "plt.ylabel('AGN remnant candidate')\n",
    "plt.xlabel('AGN remnant candidate predicted')\n",
    "plt.savefig(os.path.join(paper_fig_dir,'confusion.pdf'),bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Recall:\", cm[1,1]/(cm[1,0]+cm[1,1]), cm[1,0],cm[1,1])\n",
    "\n",
    "report = classification_report(labels_test, pred, output_dict=True,\n",
    "                            target_names=['noncandidate','AGN remnant candidate'])\n",
    "print(\"Latex performance report for given prediction threshold:\")\n",
    "print('Performance of trained RF on test set with prediction threshold set to guarantee full recall of the AGN remnant candidates.')\n",
    "print(classification_report_to_latex(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed278e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F2-score on test set:\n",
    "def fb(tn,fn,tp,fp,b=2):\n",
    "    return ((1+b**2)*tp) / ((1+b**2)*tp + fn*b**2 + fp)\n",
    "\n",
    "print(\"Train set F2-score is\", fb(cm_train[0,0],cm_train[1,0],cm_train[1,1],cm_train[0,1],b=2))\n",
    "print(\"Test set F2-score is\", fb(cm[0,0],cm[1,0],cm[1,1],cm[0,1],b=2))\n",
    "oud = cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1]\n",
    "nieuw=cm[0,1]+cm[1,1]\n",
    "print(oud,nieuw)\n",
    "print(f\"Reducing visual inspection by {(nieuw-oud)/oud:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77af231d",
   "metadata": {},
   "source": [
    "## Plot false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20512582",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_to_iloc = {sn:idx for idx, sn in enumerate(hetdex_SFGfiltered_cat.Source_Name.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_from_sn(sn):\n",
    "    idx = sn_to_iloc[sn]\n",
    "    cutout = hetdex_SFGfiltered_cutouts[idx]\n",
    "    plt.imshow(cutout)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "last_was_fp = False\n",
    "for i, (prediction, sn) in enumerate(zip(pred, sourcenames_test)):\n",
    "    if i>400: break\n",
    "    if prediction:\n",
    "        if not sn in cali_SFGfiltered_cat.Source_Name.values:\n",
    "            print(\"False positive: Could be remnant?\")\n",
    "            plot_from_sn(sn)\n",
    "            last_was_fp = True\n",
    "        else:\n",
    "            continue\n",
    "            print(\"True positive (candidate)?\")\n",
    "            plot_from_sn(sn)\n",
    "            last_was_fp = True\n",
    "    else:\n",
    "        if not sn in cali_SFGfiltered_cat.Source_Name.values:\n",
    "            continue\n",
    "            if last_was_fp:\n",
    "                print(\"True negative\")\n",
    "                plot_from_sn(sn)\n",
    "                last_was_fp = False\n",
    "        else:\n",
    "            print(\"False negative (weird candidate)?\")\n",
    "            plot_from_sn(sn)\n",
    "            last_was_fp = True\n",
    "#for i, (prediction, sn) in enumerate(zip(pred, sourcenames_test)):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518bf27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cutout_from_sn(sn):\n",
    "    idx = sn_to_iloc[sn]\n",
    "    cutout = hetdex_SFGfiltered_cutouts[idx]\n",
    "    return cutout\n",
    "\n",
    "ll = np.shape(cutout)[0]\n",
    "w = int(ll/np.sqrt(2))\n",
    "ss=int((ll-w)/2)\n",
    "limit=6\n",
    "# True positives\n",
    "rnames = cali_SFGfiltered_cat.Source_Name.values\n",
    "tp_cutouts =np.array([cutout_from_sn(sn) for prediction, sn in zip(pred, sourcenames_test)\n",
    "      if prediction and (sn in rnames)])\n",
    "# Draw random sample with replacement\n",
    "np.random.seed(random_seed)\n",
    "draws = np.random.choice(len(tp_cutouts), size=limit**2, replace=False)\n",
    "tp_cutouts = tp_cutouts[draws]\n",
    "ww = int(np.ceil(np.sqrt(len(tp_cutouts))))\n",
    "f, a = plt.subplots(ww,ww,figsize=(10,10),constrained_layout=True)\n",
    "plt.suptitle('True positives (AGN remnant candidates)')\n",
    "[axx.set_axis_off() for axx in a.ravel()]\n",
    "for i, axx in enumerate(a.ravel()):\n",
    "    if i<len(tp_cutouts):\n",
    "        im = deepcopy(tp_cutouts[i])\n",
    "        im = im[ss:-ss,ss:-ss]\n",
    "        axx.text(0,0,f'TP{i+1}',color='white',ha='left',va='bottom',size=12)        \n",
    "        axx.imshow(im, origin='lower')\n",
    "plt.savefig(os.path.join(paper_fig_dir,'output_examples_TP.pdf'),bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# False positives (maybe candidates?)\n",
    "rnames = cali_SFGfiltered_cat.Source_Name.values\n",
    "fp_cutouts =np.array([cutout_from_sn(sn) for prediction, sn in zip(pred, sourcenames_test)\n",
    "      if prediction and (sn not in rnames)])\n",
    "fp_names =np.array([sn for prediction, sn in zip(pred, sourcenames_test)\n",
    "    if prediction and (sn not in rnames)])\n",
    "np.random.seed(random_seed)\n",
    "draws = np.random.choice(len(fp_cutouts), size=limit**2, replace=False)\n",
    "fp_cutouts = fp_cutouts[draws]\n",
    "fp_names = fp_names[draws]\n",
    "ww = int(np.ceil(np.sqrt(len(fp_cutouts))))\n",
    "f, a = plt.subplots(ww,ww,figsize=(10,10),constrained_layout=True)\n",
    "[axx.set_axis_off() for axx in a.ravel()]\n",
    "for i, axx in enumerate(a.ravel()):\n",
    "    if i<len(fp_cutouts):\n",
    "        im = deepcopy(fp_cutouts[i])\n",
    "        im = im[ss:-ss,ss:-ss]\n",
    "        axx.text(0,0,f'FP{i+1}',color='white',ha='left',va='bottom',size=12)        \n",
    "        axx.imshow(im, origin='lower')\n",
    "plt.suptitle('False positives (more likely candidates)')\n",
    "plt.savefig(os.path.join(paper_fig_dir,'output_examples_FP.pdf'),bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# True negatives\n",
    "rnames = cali_SFGfiltered_cat.Source_Name.values\n",
    "tn_cutouts =np.array([cutout_from_sn(sn) for prediction, sn in zip(pred, sourcenames_test)\n",
    "      if (not prediction) and (sn not in rnames)])\n",
    "tn_names =np.array([sn for prediction, sn in zip(pred, sourcenames_test)\n",
    "      if (not prediction) and (sn not in rnames)])\n",
    "np.random.seed(random_seed)\n",
    "draws = np.random.choice(len(tn_cutouts), size=limit**2, replace=False)\n",
    "tn_cutouts = tn_cutouts[draws]\n",
    "tn_names = tn_names[draws]\n",
    "ww = int(np.ceil(np.sqrt(len(fp_cutouts))))\n",
    "f, a = plt.subplots(ww,ww,figsize=(10,10),constrained_layout=True)\n",
    "[axx.set_axis_off() for axx in a.ravel()]\n",
    "for i, axx in enumerate(a.ravel()):\n",
    "    if i<len(fp_cutouts):\n",
    "        im = deepcopy(tn_cutouts[i])\n",
    "        im = im[ss:-ss,ss:-ss]\n",
    "        axx.text(0,0,f'TN{i+1}',color='white',ha='left',va='bottom',size=12)        \n",
    "        axx.imshow(im, origin='lower')\n",
    "plt.suptitle('True negatives (less likely candidates)')\n",
    "plt.savefig(os.path.join(paper_fig_dir,'output_examples_TN.pdf'),bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c23b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = deepcopy(hetdex_SFGfiltered_cat)\n",
    "cat = cat.set_index('Source_Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14258e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write names to file \n",
    "with open('36false_positives_noTotalFlux.txt','w') as f:\n",
    "    print('#, Source Name, RA [deg], DEC [deg]', file=f)\n",
    "    for ii, sn in enumerate(fp_names):\n",
    "        ra = cat.loc[sn].RA\n",
    "        dec = cat.loc[sn].DEC\n",
    "        print(f'FP{ii+1}, {sn}, {ra}, {dec}', file=f)\n",
    "        \n",
    "with open('36true_negatives_noTotalFlux.txt','w') as f:\n",
    "    print('#, Source Name, RA [deg], DEC [deg]', file=f)\n",
    "    for ii, sn in enumerate(tn_names):\n",
    "        ra = cat.loc[sn].RA\n",
    "        dec = cat.loc[sn].DEC\n",
    "        print(f'TN{ii+1}, {sn}, {ra}, {dec}', file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1793a73a",
   "metadata": {},
   "source": [
    "## Test classifier significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb485392",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "# Evaluate the significance of a cross-validated score with permutations.\n",
    "start =time.time()\n",
    "score_test, perm_scores_test, pvalue_test = custom_permutation_test_score(\n",
    "    best_rf, features_train, labels_train, cv=cv, scoring=scoring,\n",
    "    n_permutations=1000, random_state=random_seed)\n",
    "print(f\"Time taken: {time.time()-start:.0f} sec\")\n",
    "score_test,pvalue_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8846c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "ax.hist(perm_scores_test, density=False, histtype='step',linewidth=3)\n",
    "ax.axvline(score_test, ls=\"--\", color=\"r\",linewidth=3)\n",
    "score_label = f\"F2-score on\\n original data: {score_test*100:.1f}%\\n(p-value: {pvalue_test:.3f})\"\n",
    "ax.text(score_test-0.02, 200, score_label, fontsize=12,ha='right',va='top')\n",
    "ax.set_xlabel(f\"F2-score\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "plt.savefig(os.path.join(paper_fig_dir, \"test_score_151vshetdex_f2score.pdf\"),bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675a158a",
   "metadata": {},
   "source": [
    "## Test permutation feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26fa4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "# Find out Permutation importance for feature evaluation\n",
    "n_repeats=40\n",
    "start =time.time()\n",
    "result = permutation_importance(\n",
    "    best_rf, features_train2, labels_train, n_repeats=n_repeats, \n",
    "    scoring=scoring,\n",
    "    random_state=random_seed, n_jobs=-1)\n",
    "\n",
    "sorted_importances_idx = result.importances_mean.argsort()\n",
    "importances_train = pd.DataFrame(\n",
    "    result.importances[sorted_importances_idx].T,\n",
    "    columns=feature_list[sorted_importances_idx],\n",
    ")\n",
    "\n",
    "result = permutation_importance(\n",
    "    best_rf, features_test2, labels_test, n_repeats=n_repeats, \n",
    "        scoring=scoring,\n",
    "    random_state=random_seed, n_jobs=-1)\n",
    "sorted_importances_idx = result.importances_mean.argsort()\n",
    "importances_test = pd.DataFrame(\n",
    "    result.importances[sorted_importances_idx].T,\n",
    "    columns=feature_list[sorted_importances_idx],\n",
    ")\n",
    "\n",
    "print(f\"Time taken: {time.time()-start:.0f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 10})\n",
    "ax = importances_train.plot.box(vert=False, whis=10,figsize=(8,4))\n",
    "ax.set_title(\"Permutation Importances (train set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(f\"Decrease in F2-score when permutating feature\",loc='right')\n",
    "plt.savefig(os.path.join(paper_fig_dir,\"perm_train_id370.pdf\"),bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "ax = importances_test.plot.box(vert=False, whis=10,figsize=(8,4))\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(f\"Decrease in F2-score when permutating feature\",loc='right')\n",
    "plt.savefig(os.path.join(paper_fig_dir,\"perm_test_id370.pdf\"),bbox_inches='tight')\n",
    "plt.show()\n",
    "total=[]\n",
    "for label,val in feature_importances:\n",
    "    print(f\"{label},\")\n",
    "    total+=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c37ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
